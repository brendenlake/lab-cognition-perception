
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8. Describing Data &#8212; Lab in C&amp;P (Fall 2021)</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nyustyle.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9. Samples, populations and sampling" href="../08/01-sampling.html" />
    <link rel="prev" title="7. Visualizing Data" href="../06/00-plots.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/artificialintelligence.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Lab in C&P (Fall 2021)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../course-content/syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../course-content/schedule.html">
   Schedule
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://edstem.org/us/courses/8295/discussion/">
   EdStem
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Textbook
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00/00-cogsci.html">
   1. What is Cognitive Science and how do we study it?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01/00-whystats.html">
   2. Why do we have to learn statistics?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02/00-jupyter.html">
   3. Introduction to Jupyter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03/00-python.html">
   4. Intro to Python for Psychology Undergrads
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04/00-researchdesign.html">
   5. A brief introduction to research design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05/00-data.html">
   6. The Format and Structure of Digital Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06/00-plots.html">
   7. Visualizing Data
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   8. Describing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08/01-sampling.html">
   9. Samples, populations and sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/00-hypothesistesting.html">
   10. Hypothesis testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10/00-ttest.html">
   11. Comparing one or two means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11/00-inferences-from-behavior.html">
   12. Measuring Behavior
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../21/00-ethics-irb.html">
   13. Research Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../13/00-linearregression.html">
   14. Linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../14/00-logisticregression.html">
   15. Logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../15/00-mixed-effect.html">
   16. Linear Mixed Effect Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../16/00-mentalsimulation.html">
   17. Mental Imagery, Mental Simulation, and Mental Rotation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../17/00-mri.html">
   18. Magnetic Resonance Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../24/00-what-next.html">
   19. What Next?
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Labs &amp; Homeworks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00/cogsci-ica.html">
   Intro to CogSci ICA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../homeworks/Homework1.html">
   Intro to Jupyter (HW1)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tips &amp; Tricks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../tips/pythonresources.html">
   Python Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tips/plottingresources.html">
   Plotting in Python Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tips/fortyforloops.html">
   Intro to For loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tips/nyu-jupyterhub.html">
   NYU JupyterHub Setup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tips/ultimate-guide-ttest-python.html">
   Ultimate t-test guide
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../LICENSE.html">
   License
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/chapters/07/00-describingdata.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://psychua-46-fall.rcnyu.org//hub/user-redirect/git-pull?repo=https://github.com/executablebooks/jupyter-book&urlpath=tree/jupyter-book/chapters/07/00-describingdata.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-dataset">
   8.1. Example Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measures-of-central-tendency">
   8.2. Measures of Central Tendency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mode">
     8.2.1. Mode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#median">
     8.2.2. Median
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean">
     8.2.3. Mean
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-median-or-mode-what-s-the-difference-when-should-i-use-one-or-the-other">
     8.2.4. Mean, median or mode? What’s the difference? When should I use one or the other?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measures-of-variability">
   8.3. Measures of variability
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#range">
     8.3.1. Range
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interquartile-range">
     8.3.2. Interquartile range
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#variance">
     8.3.3. Variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-deviation">
     8.3.4. Standard deviation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-measure-to-use">
     8.3.5. Which measure to use?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remember-to-look-at-your-data">
   8.4. Remember to look at your data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summarizing-at-different-levels">
   8.5. Summarizing at different levels
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-your-own-custom-descriptive-statistics">
   8.6. Creating your own custom descriptive statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlations-and-covariance">
   8.7. Correlations and Covariance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-strength-and-direction-of-a-relationship">
     8.7.1. The strength and direction of a relationship
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-correlation-coefficient">
     8.7.2. The correlation coefficient
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calculating-correlations-in-python">
     8.7.3. Calculating correlations in Python
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-a-correlation">
     8.7.4. Interpreting a correlation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spearman-s-rank-correlations">
     8.7.5. Spearman’s rank correlations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reporting-descriptive-statistics">
   8.8. Reporting Descriptive Statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   8.9. Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   8.10. References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span> <span class="c1"># for the Jupyter book chapter</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="describing-data">
<h1><span class="section-number">8. </span>Describing Data<a class="headerlink" href="#describing-data" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This chapter by <a class="reference external" href="https://gureckislab.org/~gureckis">Todd M. Gureckis</a> and is released under the <a class="reference internal" href="../../LICENSE.html"><span class="doc std std-doc">license for this book</span></a>. Elements of this chapter are adapted from Matthew Crump’s excellent <a class="reference external" href="https://crumplab.github.io/statistics/">Answering questions with data</a> book <span id="id1">[<a class="reference internal" href="../08/01-sampling.html#id58">Crump <em>et al.</em>, 2019</a>]</span> which also draws from from Danielle Navarro’s excellent <a class="reference external" href="https://learningstatisticswithr.com">Learning Statistics with R</a> book <span id="id2">[<a class="reference internal" href="../08/01-sampling.html#id59">Navarro, 2011</a>]</span>.  One major change is the code was adapted to use python and jupyter.  In addition the introduction was replaced/shortened.  A chapter on descriptive statistics and correlation were merged.</p>
</div>
<p>We previously considered ways to visualize data using computer graphics.  Visualizations help us see patterns in data and to verify our understanding.  Visualization also sometimes help to summarize data in a more compact form than looking at the raw data.  However, in some cases it is more precise to summarize our data using numbers which we call <strong>descriptive statistics</strong>.</p>
<p>Descriptive statistics are probably the simplest and most straightforward aspect of statistical data analysis.  We are simplying taking a collection of numbers and computing a new number which summarizes the data in some way.  There are many different descriptive statistics and which is most appropriate depends a lot on the nature of the data and what you want to communicate about the data to others.  Simply put, a descriptive statistic is a number, computed on a collection of numbers (i.e., data), that captures something important about the data.</p>
<div style="text-align: center">
    <img src="./images/descriptivestats.png" width="500">
</div>
<p>Academic papers in psychology are littered with descriptive statitics even if inferential statistics (things we will discuss later) end up being the “flashiest” findings.  We need descriptive statistics to tell readers of our papers or audience members at our talks/posters what basically went on in a dataset without showing them all of the data or giving too many plots/visualizations.  Descriptive statistics tend to be quick, easy to convey summaries.  In addition, since they are usually numbers, they admit easy comparison to one another.</p>
<p>There are lots of different descriptive statistics.  The one you are perhaps most familiar with is the arithmetic average or <em>mean</em> (e.g., when you compute your average grade for the class it summarizes your performance in the class across many different assignments).  However there are many others we will discuss, and it fact it is possible to compute new statistics yourself!</p>
<p>Most of the statistical concepts in this chapter should be review if you have taken an introductory statistics course in psychology.  What you will learn by reading carefully is how to easily compute descriptive statistics for different datasets using Python and Pandas, a review of the merits and meaning of various statistics, and how to report them in papers and talks.</p>
<div class="section" id="example-dataset">
<h2><span class="section-number">8.1. </span>Example Dataset<a class="headerlink" href="#example-dataset" title="Permalink to this headline">¶</a></h2>
<p>We begin by loading an example dataset into a Pandas dataframe that we will use as an example throughout this chapter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://tinyurl.com/yya6yyt8&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">About the data</p>
<p>The data is from the <a class="reference external" href="http://gureckislab.org/omni/index.html">OMNI</a> project which examines how people learn and forget information.  In this specific dataset a set of participants studied a list of 45 Lithuanian-English vocabulary words five times for each word.  Immediately after study, participant gave each word pair a “judgement-of-learning” (JOL) rating of how likely they felt they would remember this pair at a later test.  They then came back for a test session several hours later (depending on a between-subject condition) and were presented with the Lithuanian word of each pair and asked to type in the corresponding English word.</p>
<p>The columns of the dataset are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">delay_group</span></code>: the approximate time betwen the study to recall test for this participant (Note that the exact time between study and test for a particular person should be obtained from the included timestamps)</p>
<ul>
<li><p>A: immediate recall after end of study and JOL blocks</p></li>
<li><p>C: 24h study-recall lag</p></li>
<li><p>E: 48h study-recall lag (n = 1, due to an error)</p></li>
<li><p>F: 72h study-recall lag</p></li>
<li><p>PRISMAF: 72h study-recall lag (study session in an MRI scanner)</p></li>
<li><p>H: 168h study-recall lag</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">participant_id</span></code>: unique identifier for each participant (delay-group + numeric)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lith_word_studied</span></code>: the lithuanian word in a studied pair</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eng_word_studied</span></code>: the english word in a studied pair</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">studyN_start</span></code>: a numeric timestamp in seconds for the start time of study trial N  (Note that all study events were four seconds duration)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jol_start</span></code>: a numeric timestamp in seconds for the start time of the JOL trial</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">recall_trial</span></code>: a numeric timestamp in seconds for the start time of the recall trial</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jol_value</span></code>: numeric responses from 0-100 indicating confidence that a given word will be remembered</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eng_word_response</span></code>: the participant’s english response for a given recall test trial</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">recall_accuracy</span></code>: the participant’s recall accuracy</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">study_test_lag</span></code>: the time between the 5th study repetition and the recall trial for the given word</p></li>
</ul>
</div>
<p>We can first verify the columns and type of data within each column of the loaded dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lith_word_studied</th>
      <th>eng_word_studied</th>
      <th>participant_id</th>
      <th>delay_group</th>
      <th>study1_start</th>
      <th>study2_start</th>
      <th>study3_start</th>
      <th>study4_start</th>
      <th>study5_start</th>
      <th>jol_start</th>
      <th>recall_start</th>
      <th>jol_value</th>
      <th>eng_word_response</th>
      <th>recall_accuracy</th>
      <th>study_test_lag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>pastatas</td>
      <td>building</td>
      <td>A1</td>
      <td>A</td>
      <td>1461597222</td>
      <td>1461598097</td>
      <td>1461598653</td>
      <td>1461599383</td>
      <td>1461599951</td>
      <td>1461600711</td>
      <td>1461601222</td>
      <td>100</td>
      <td>building</td>
      <td>1</td>
      <td>21.183333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>mesa</td>
      <td>meat</td>
      <td>A1</td>
      <td>A</td>
      <td>1461597234</td>
      <td>1461598070</td>
      <td>1461598710</td>
      <td>1461599353</td>
      <td>1461599975</td>
      <td>1461600707</td>
      <td>1461601232</td>
      <td>100</td>
      <td>meat</td>
      <td>1</td>
      <td>20.950000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>kreida</td>
      <td>chalk</td>
      <td>A1</td>
      <td>A</td>
      <td>1461597248</td>
      <td>1461598054</td>
      <td>1461598669</td>
      <td>1461599403</td>
      <td>1461599965</td>
      <td>1461600699</td>
      <td>1461601238</td>
      <td>75</td>
      <td>sword</td>
      <td>0</td>
      <td>21.216667</td>
    </tr>
    <tr>
      <th>3</th>
      <td>bugnas</td>
      <td>drum</td>
      <td>A1</td>
      <td>A</td>
      <td>1461597262</td>
      <td>1461598085</td>
      <td>1461598683</td>
      <td>1461599393</td>
      <td>1461599985</td>
      <td>1461600719</td>
      <td>1461601235</td>
      <td>100</td>
      <td>drum</td>
      <td>1</td>
      <td>20.833333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>muilas</td>
      <td>soap</td>
      <td>A1</td>
      <td>A</td>
      <td>1461597274</td>
      <td>1461598111</td>
      <td>1461598700</td>
      <td>1461599369</td>
      <td>1461599995</td>
      <td>1461600716</td>
      <td>1461601249</td>
      <td>100</td>
      <td>soap</td>
      <td>1</td>
      <td>20.900000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We will start with a very simple and broad approach to computing descriptive statistics using the <code class="docutils literal notranslate"><span class="pre">.describe()</span></code> method of Pandas.  This function computes several descriptive statistics for each column of a dataset.  Which statistics is computed in the output depends somewhat on the nature of the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>study1_start</th>
      <th>study2_start</th>
      <th>study3_start</th>
      <th>study4_start</th>
      <th>study5_start</th>
      <th>jol_start</th>
      <th>recall_start</th>
      <th>jol_value</th>
      <th>recall_accuracy</th>
      <th>study_test_lag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>8.550000e+03</td>
      <td>8.550000e+03</td>
      <td>8.550000e+03</td>
      <td>8.550000e+03</td>
      <td>8.550000e+03</td>
      <td>8.550000e+03</td>
      <td>8.550000e+03</td>
      <td>8550.000000</td>
      <td>8550.000000</td>
      <td>8550.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.481107e+09</td>
      <td>1.481108e+09</td>
      <td>1.481109e+09</td>
      <td>1.481109e+09</td>
      <td>1.481110e+09</td>
      <td>1.481111e+09</td>
      <td>1.481385e+09</td>
      <td>61.665146</td>
      <td>0.418129</td>
      <td>4583.718248</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.244130e+07</td>
      <td>1.244130e+07</td>
      <td>1.244131e+07</td>
      <td>1.244130e+07</td>
      <td>1.244130e+07</td>
      <td>1.244149e+07</td>
      <td>1.248592e+07</td>
      <td>31.876645</td>
      <td>0.493280</td>
      <td>3585.115929</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.461597e+09</td>
      <td>1.461598e+09</td>
      <td>1.461599e+09</td>
      <td>1.461599e+09</td>
      <td>1.461600e+09</td>
      <td>1.461601e+09</td>
      <td>1.461601e+09</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>10.050000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.471894e+09</td>
      <td>1.471895e+09</td>
      <td>1.471896e+09</td>
      <td>1.471897e+09</td>
      <td>1.471897e+09</td>
      <td>1.471898e+09</td>
      <td>1.472154e+09</td>
      <td>37.000000</td>
      <td>0.000000</td>
      <td>1405.112500</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.479028e+09</td>
      <td>1.479029e+09</td>
      <td>1.479030e+09</td>
      <td>1.479030e+09</td>
      <td>1.479031e+09</td>
      <td>1.479032e+09</td>
      <td>1.479421e+09</td>
      <td>66.000000</td>
      <td>0.000000</td>
      <td>4268.191666</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.488220e+09</td>
      <td>1.488221e+09</td>
      <td>1.488221e+09</td>
      <td>1.488222e+09</td>
      <td>1.488222e+09</td>
      <td>1.488223e+09</td>
      <td>1.488492e+09</td>
      <td>91.000000</td>
      <td>1.000000</td>
      <td>9983.912500</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.516474e+09</td>
      <td>1.516475e+09</td>
      <td>1.516475e+09</td>
      <td>1.516476e+09</td>
      <td>1.516477e+09</td>
      <td>1.516478e+09</td>
      <td>1.516735e+09</td>
      <td>100.000000</td>
      <td>1.000000</td>
      <td>11518.816670</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>If you look at the rows of the resulting dataframe the include the <code class="docutils literal notranslate"><span class="pre">count</span></code> (the number of rows in that column), <code class="docutils literal notranslate"><span class="pre">std</span></code> the standard deviaion of the values, <code class="docutils literal notranslate"><span class="pre">min</span></code> the minimum value in the column, <code class="docutils literal notranslate"><span class="pre">50%</span></code> which is the median (and <code class="docutils literal notranslate"><span class="pre">25%</span></code> and <code class="docutils literal notranslate"><span class="pre">75%</span></code> which show alternative quartiles), the <code class="docutils literal notranslate"><span class="pre">mean</span></code>, and the <code class="docutils literal notranslate"><span class="pre">max</span></code>.</p>
<p>Also note that several columns in the original dataframe such as <code class="docutils literal notranslate"><span class="pre">participant_id</span></code> is missing from this output.  This is because the set of descriptive statistics here only apply to columns made up with real numbers (you can’t take the mean of a string).  To get descriptive statistics for individual columns we can first <em>select</em> a column and then do <code class="docutils literal notranslate"><span class="pre">.describe()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;participant_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count     8550
unique     190
top        H47
freq        45
Name: participant_id, dtype: object
</pre></div>
</div>
</div>
</div>
<p>The statistics for discrete data include the number of rows (<code class="docutils literal notranslate"><span class="pre">count</span></code>), the number of unique values (<code class="docutils literal notranslate"><span class="pre">unique</span></code>), the most frequent value (<code class="docutils literal notranslate"><span class="pre">H47</span></code>), and the frequency of the most common elements (<code class="docutils literal notranslate"><span class="pre">freq</span></code>).  From this we can see there is 190 participants in this data set and 8550 trials.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.describe()</span></code> dataframe method is sort of the “ultra-simple” descriptive statistic function.  However as we will step through in the following sections there are specific methods for specific statistics as well as the ability to write your own custom descriptive statistics.  As one example <code class="docutils literal notranslate"><span class="pre">.mean()</span></code> computes the mean within each column (if the column is a number and not a string):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>study1_start       1.481107e+09
study2_start       1.481108e+09
study3_start       1.481109e+09
study4_start       1.481109e+09
study5_start       1.481110e+09
jol_start          1.481111e+09
recall_start       1.481385e+09
jol_value          6.166515e+01
recall_accuracy    4.181287e-01
study_test_lag     4.583718e+03
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="measures-of-central-tendency">
<h2><span class="section-number">8.2. </span>Measures of Central Tendency<a class="headerlink" href="#measures-of-central-tendency" title="Permalink to this headline">¶</a></h2>
<p>Measures of central tendency have one important summary goal: to reduce a pile of numbers to a single number that summarizes in some sense the average or typical value. Take a moment here to listen to this interesting National Public Radio <a class="reference external" href="https://www.npr.org/sections/money/">Planet Money</a> podcast about “the modal american” which discusses exactly how difficult it can be to compute the average or typical value of some population or dataset.  After you listen, test your understanding with the questions below.</p>
<iframe src="https://www.npr.org/player/embed/755191639/755262760" width="100%" height="290" frameborder="0" scrolling="no" title="NPR embedded audio player"></iframe>
<div class="hint admonition">
<p class="admonition-title">Test yourself: What is the median age of an American?</p>
<ul class="simple">
<li><p>26</p></li>
<li><p>38</p></li>
<li><p>56</p></li>
<li><p>78</p></li>
</ul>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Click the button to reveal the answer!</p>
<p>Around 5:52 in the podcast they discuss the distribution of ages in the American population, and the bimodal hump which is the Millenials (“echo boomers”) and the Boomers.  The median age is 38 but their analysis but fewer Americans are this age.  The most common (modal) age is 26.</p>
</div>
<div class="hint admonition">
<p class="admonition-title">Test yourself: When they analyze data in terms of multiple traits and category “buckets” who was the modal American?</p>
<ul class="simple">
<li><p>a child, gen-z, unmarried, no college degree, unemployed</p></li>
<li><p>a college student, married, mid-20s</p></li>
<li><p>a retiree, late 60s, unmarried, college educated</p></li>
</ul>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Click the button to reveal the answer!</p>
<p>Around 13:47 in the podcast they discuss that all the children in the US fall into one of the categories because the categories were slanted towards adults (employed, college, etc…).
The modal american in their analysis actually is male, gen-x, 39-54 years old, lives in suburbs, did not complete college, white, married, working full time, household income $75-165k/year.  Partly because this middle age generation is more homogenous (generally working full-time, etc…) while older and younger generations have more varied work and marriage relationships.</p>
</div>
<p>Ok with some of the trickiness of defining a central tendency for real data, let’s look at the traditional statistics for this.</p>
<div class="section" id="mode">
<h3><span class="section-number">8.2.1. </span>Mode<a class="headerlink" href="#mode" title="Permalink to this headline">¶</a></h3>
<p>The <strong>mode</strong> is the most frequently occurring number in your measurement. That is it. How do you find it? You have to count the number of times each number appears in your measure, then whichever one occurs the most, is the mode.</p>
<blockquote>
<div><p>Example: 1 1 1 2 3 4 5 6</p>
</div></blockquote>
<p>The mode of the above set is 1, which occurs three times. Every other number only occurs once.</p>
<p>OK fine. What happens here:</p>
<blockquote>
<div><p>Example: 1 1 1 2 2 2 3 4 5 6</p>
</div></blockquote>
<p>Hmm, now 1 and 2 both occur three times each. What do we do? We say there are two modes, and they are 1 and 2.</p>
<p>Why is the mode a measure of central tendency? Well, when we ask, “what are my numbers like”, we can say, “most of the number are, like a 1 (or whatever the mode is)”.</p>
<p>Is the mode a good measure of central tendency? That depends on your numbers. For example, consider these numbers</p>
<blockquote>
<div><p>1 1 2 3 4 5 6 7 8 9</p>
</div></blockquote>
<p>Here, the mode is 1 again, because there are two 1s, and all of the other numbers occur once. But, are most of the numbers like, a 1. No, they are mostly not 1s.</p>
<p>When is the mode a good summary of a set of data?  Well generally mode is useful for things that have a chance of repeating.  For instance since we usually think of people’s age in whole numbers (36, 24, 56, etc…) then we can find the modal age to find the most common age.  However, it might make less sense on more fine-grained measurements.  For instance if you recorded the altitude of every US city to the closest millimeter it might not make sense to report the mode since at the scale of a millimeter maybe very few cities have the same value (and thus there are many modes with only one occurence).  As the podcast above points out the mode is good for gauging “who is most common/typical in a population” and that is why talking about the “modal american” is an appealing statistical concept.</p>
<p>How do we compute the mode in Pandas.  Well you saw already that when you call <code class="docutils literal notranslate"><span class="pre">.describe()</span></code> on a column that has nominal (i.e., string data) it reports the most common value or mode.  You can request this statistic directly like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    100
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>This shows us that 100 is the most common judgment of learning (JOL) rating that people gave overall.  If we ask for the modal <code class="docutils literal notranslate"><span class="pre">participant_id</span></code> that is the id of the subject with the most trials in the data frame (i.e., they appear in the most rows).  However, since all subjects had exactly 45 trials there are multiple modes in the participant id column.  In fact if we run that command we get 190 different modes each picking out a different subject with 45 trials.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;participant_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0             A1
1            A10
2            A11
3            A12
4            A13
         ...    
185    PRISMAF28
186    PRISMAF29
187    PRISMAF30
188    PRISMAF31
189    PRISMAF32
Length: 190, dtype: object
</pre></div>
</div>
</div>
</div>
<p>The mode is the <strong>value</strong> which is most common.  Sometimes you want to know how often the modal value appears.  The <code class="docutils literal notranslate"><span class="pre">.value_counts()</span></code> function computes a tally of how often each value repeats in a list sorted from biggest to smallest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100    1616
50      370
80      324
90      308
70      302
       ... 
12       23
3        22
17       20
2        20
27       17
Name: jol_value, Length: 101, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Thus the first entry of this series shows that the value 100 appears 1616 times.  It also shows the second most common rating is 50 which appears 370 times.  If you only one the count for the mode there a few tricks you could do, e.g., we can use <code class="docutils literal notranslate"><span class="pre">.iat[0]</span></code> to extract the first entry to the <code class="docutils literal notranslate"><span class="pre">.value_counts()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">iat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1616
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="median">
<h3><span class="section-number">8.2.2. </span>Median<a class="headerlink" href="#median" title="Permalink to this headline">¶</a></h3>
<p>The <strong>median</strong> is the exact middle of the data. After all, we are asking about central tendency, so why not go to the center of the data and see where we are. What do you mean middle of the data? Let’s look at these numbers:</p>
<blockquote>
<div><p>1 5 4 3 6 7 9</p>
</div></blockquote>
<p>Umm, OK. So, three is in the middle? Isn’t that kind of arbitrary. Yes. Before we can compute the median, we need to order the numbers from smallest to largest.</p>
<blockquote>
<div><p>1 3 4 <strong>5</strong> 6 7 9</p>
</div></blockquote>
<p>Now, 5 is in the middle. And, by middle we mean in the middle. There are three numbers to the left of 5, and three numbers to the right. So, five is definitely in the middle.</p>
<p>OK fine, but what happens when there aren’t an even number of numbers? Then the middle will be missing right? Let’s see:</p>
<blockquote>
<div><p>1 2 3 4 5 6</p>
</div></blockquote>
<p>There is no number between 3 and 4 in the data, the middle is empty. In this case, we compute the median by figuring out the number in between 3 and 4. So, the median would be 3.5.</p>
<p>Is the median a good measure of central tendency? Sure, it is often very useful. One property of the median is that it stays in the middle even when some of the other numbers get really weird. For example, consider these numbers:</p>
<blockquote>
<div><p>1 2 3 4 4 4 <strong>5</strong> 6 6 6 7 7 1000</p>
</div></blockquote>
<p>Most of these numbers are smallish, but the 1000 is a big old weird number, very different from the rest. The median is still 5, because it is in the middle of these ordered numbers. We can also see that five is pretty similar to most of the numbers (except for 1000). So, the median does a pretty good job of representing most of the numbers in the set, and it does so even if one or two of the numbers are very different from the others.</p>
<p>Finally, <strong>outlier</strong> is a term will we use to describe numbers that appear in data that are very different from the rest. 1000 is an outlier, because it lies way out there on the number line compared to the other numbers. What to do with outliers is another topic we discuss later.</p>
<p>We can compute the median of a single column just like we computed the mean using Pandas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>66.0
</pre></div>
</div>
</div>
</div>
<p>As you can see the median is quite different than the mode.  The most common JOL rating was 100 but the median is 66!</p>
</div>
<div class="section" id="mean">
<h3><span class="section-number">8.2.3. </span>Mean<a class="headerlink" href="#mean" title="Permalink to this headline">¶</a></h3>
<p>Perhaps the most well known measure of central tendency is the <strong>mean</strong> or arithmetic average.  It is best represented as a formula where we sum up the numbers then divide by the number of numbers:</p>
<p><span class="math notranslate nohighlight">\(Mean = \bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{N}\)</span></p>
<p>The <span class="math notranslate nohighlight">\(\sum\)</span> symbol is called <strong>sigma</strong>, and it stands for the operation of summing. The little “i” on the bottom, and the little “n” on the top refers to all of the numbers in the set, from the first number “i” to the last number “n”. The letters are just arbitrary labels, called <strong>variables</strong> that we use for descriptive purposes. The <span class="math notranslate nohighlight">\(x_{i}\)</span> refers to individual numbers in the set. We sum up all of the numbers, then divide the sum by <span class="math notranslate nohighlight">\(N\)</span>, which is the total number of numbers. Sometimes you will see <span class="math notranslate nohighlight">\(\bar{X}\)</span> to refer to the mean of all of the numbers.</p>
<p>In plain English, the formula looks like:</p>
<p><span class="math notranslate nohighlight">\(mean = \frac{\text{Sum of my numbers}}{\text{Count of my numbers}}\)</span></p>
<p>Let’s compute the mean for these five numbers:</p>
<blockquote>
<div><p>3 7 9 2 6</p>
</div></blockquote>
<p>Add em up:</p>
<blockquote>
<div><p>3+7+9+2+6 = 27</p>
</div></blockquote>
<p>Count em up:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(i_{1}\)</span> = 3, <span class="math notranslate nohighlight">\(i_{2}\)</span> = 7, <span class="math notranslate nohighlight">\(i_{3}\)</span> = 9, <span class="math notranslate nohighlight">\(i_{4}\)</span> = 2, <span class="math notranslate nohighlight">\(i_{5}\)</span> = 6; N=5, because <span class="math notranslate nohighlight">\(i\)</span> went from 1 to 5</p>
</div></blockquote>
<p>Divide em:</p>
<blockquote>
<div><p>mean = 27 / 5 = 5.4</p>
</div></blockquote>
<p>Or, to put the numbers in the formula, it looks like this:</p>
<p><span class="math notranslate nohighlight">\(Mean = \bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{N} = \frac{3+7+9+2+6}{5} = \frac{27}{5} = 5.4\)</span></p>
<blockquote>
<div><p>Pro tip: The mean is the one and only number that can take the place of every number in the data, such that when you add up all the equal parts, you get back the original sum of the data.</p>
</div></blockquote>
<p>Computing the mean of a column in Pandas is trivial:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>61.665146198830406
</pre></div>
</div>
</div>
</div>
<p>or all columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>study1_start       1.481107e+09
study2_start       1.481108e+09
study3_start       1.481109e+09
study4_start       1.481109e+09
study5_start       1.481110e+09
jol_start          1.481111e+09
recall_start       1.481385e+09
jol_value          6.166515e+01
recall_accuracy    4.181287e-01
study_test_lag     4.583718e+03
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mean-median-or-mode-what-s-the-difference-when-should-i-use-one-or-the-other">
<h3><span class="section-number">8.2.4. </span>Mean, median or mode? What’s the difference? When should I use one or the other?<a class="headerlink" href="#mean-median-or-mode-what-s-the-difference-when-should-i-use-one-or-the-other" title="Permalink to this headline">¶</a></h3>
<div class="figure align-default" id="fig-meanmedian">
<a class="reference internal image-reference" href="../../_images/meanmedian.png"><img alt="../../_images/meanmedian.png" src="../../_images/meanmedian.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 8.1 </span><span class="caption-text">Illustration of the intuitive difference between the mean and median</span><a class="headerlink" href="#fig-meanmedian" title="Permalink to this image">¶</a></p>
</div>
<p>Knowing how to calculate means and medians is only a part of the story. You also need to understand what each one is saying about the data, and what that implies for when you should use each one. This is illustrated in <a class="reference internal" href="#fig-meanmedian"><span class="std std-numref">Fig. 8.1</span></a> the mean is kind of like the “centre of gravity” of the data set, whereas the median is the “middle value” in the data. What this implies, as far as which one you should use, depends a little on what type of data you’ve got and what you’re trying to achieve. As a rough guide:</p>
<ul class="simple">
<li><p>If your data are nominal scale, you probably shouldn’t be using either the mean or the median. Both the mean and the median rely on the idea that the numbers assigned to values are meaningful. If the numbering scheme is arbitrary, then it’s probably best to use the mode instead.</p></li>
<li><p>If your data are ordinal scale, you’re more likely to want to use the median than the mean. The median only makes use of the order information in your data (i.e., which numbers are bigger), but doesn’t depend on the precise numbers involved. That’s exactly the situation that applies when your data are ordinal scale. The mean, on the other hand, makes use of the precise numeric values assigned to the observations, so it’s not really appropriate for ordinal data.</p></li>
<li><p>For interval and ratio scale data, either one is generally acceptable. Which one you pick depends a bit on what you’re trying to achieve. The mean has the advantage that it uses all the information in the data (which is useful when you don’t have a lot of data), but it’s very sensitive to extreme values.</p></li>
</ul>
<p>Let’s expand on that last part a little. One consequence is that there’s systematic differences between the mean and the median when the histogram is asymmetric (also known as “skewed”). This is illustrated in <a class="reference internal" href="#fig-meanmedian"><span class="std std-numref">Fig. 8.1</span></a> notice that the median (right hand side) is located closer to the “body” of the histogram, whereas the mean (left hand side) gets dragged towards the “tail” (where the extreme values are). To give a concrete example, suppose Bob (income $50,000), Kate (income $60,000) and Jane (income $65,000) are sitting at a table: the average income at the table is $58,333 and the median income is $60,000. Then Bill sits down with them (income $100,000,000). The average income has now jumped to $25,043,750 but the median rises only to $62,500. If you’re interested in looking at the overall income at the table, the mean might be the right answer; but if you’re interested in what counts as a typical income at the table, the median would be a better choice here.</p>
</div>
</div>
<div class="section" id="measures-of-variability">
<h2><span class="section-number">8.3. </span>Measures of variability<a class="headerlink" href="#measures-of-variability" title="Permalink to this headline">¶</a></h2>
<p>The statistics that we’ve discussed so far all relate to <em>central tendency</em>. That is, they all talk about which values are “in the middle” or “popular” in the data. However, central tendency is not the only type of summary statistic that we want to calculate. The second thing that we really want is a measure of the <strong><em>variability</em></strong> of the data. That is, how “spread out” are the data? How “far” away from the mean or median do the observed values tend to be?</p>
<div class="section" id="range">
<h3><span class="section-number">8.3.1. </span>Range<a class="headerlink" href="#range" title="Permalink to this headline">¶</a></h3>
<p>The <strong><em>range</em></strong> of a variable is very simple: it’s the biggest value minus the smallest value. For the OMNI JOL data, the maximum value is 100, and the minimum value is 0. We can calculate these values in R using the <code class="docutils literal notranslate"><span class="pre">max()</span></code> and <code class="docutils literal notranslate"><span class="pre">min()</span></code> functions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">range_vals</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">range_vals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
</div>
</div>
<p>Although the range is the simplest way to quantify the notion of “variability”, it’s one of the worst. We generally want our summary measure to be “robust” to outliers. If the data set has one or two extremely weird values in it, we’d like our statistics not to be unduly influenced by these cases. If we look once again at our toy example of a data set containing very extreme outliers…</p>
<p><span class="math notranslate nohighlight">\(-100,2,3,4,5,6,7,8,9,10\)</span></p>
<p>… it is clear that the range is not robust, since this has a range of 110, but if the outlier were removed we would have a range of only 8.</p>
</div>
<div class="section" id="interquartile-range">
<h3><span class="section-number">8.3.2. </span>Interquartile range<a class="headerlink" href="#interquartile-range" title="Permalink to this headline">¶</a></h3>
<p>The <strong><em>interquartile range</em></strong> (IQR) is like the range, but instead of calculating the difference between the biggest and smallest value, it calculates the difference between the 25th quantile and the 75th quantile. Probably you already know what a <strong><em>quantile</em></strong> is (they’re more commonly called percentiles), but if not: the 10th percentile of a data set is the smallest number <span class="math notranslate nohighlight">\(x\)</span> such that 10% of the data is less than <span class="math notranslate nohighlight">\(x\)</span>. In fact, we’ve already come across the idea: the median of a data set is its 50th quantile / percentile! Pandas actually provides you with a way of calculating quantiles, using the (surprise, surprise) <code class="docutils literal notranslate"><span class="pre">.quantile()</span></code> function. Let’s use it to calculate the median JOL in the OMNI dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>66.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>66.0
</pre></div>
</div>
</div>
</div>
<p>And not surprisingly, this agrees with the answer that we saw earlier with the <code class="docutils literal notranslate"><span class="pre">.median()</span></code> function. Now, we can actually input lots of quantiles at once, by specifying a list for the <code class="docutils literal notranslate"><span class="pre">probs</span></code> argument. So lets do that, and get the 25th and 75th percentile:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.75</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.25    37.0
0.75    91.0
Name: jol_value, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can just subtract them to get the IQR:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iqr</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">iqr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>54.0
</pre></div>
</div>
</div>
</div>
<p>While it’s obvious how to interpret the range, it’s a little less obvious how to interpret the IQR. The simplest way to think about it is like this: the interquartile range is the range spanned by the “middle half” of the data. That is, one quarter of the data falls below the 25th percentile, one quarter of the data is above the 75th percentile, leaving the “middle half” of the data lying in between the two. And the IQR is the range covered by that middle half.</p>
</div>
<div class="section" id="variance">
<h3><span class="section-number">8.3.3. </span>Variance<a class="headerlink" href="#variance" title="Permalink to this headline">¶</a></h3>
<p>The two measures we’ve looked at so far, the range and the interquartile range, both rely on the idea that we can measure the spread of the data by looking at the quantiles of the data. However, this isn’t the only way to think about the problem. A different approach is to select a meaningful reference point (usually the mean or the median) and then report the “typical” deviations from that reference point. What do we mean by “typical” deviation? Usually, the mean or median value of these deviations!</p>
<p>From a purely mathematical perspective, there are some solid reasons to prefer squared deviations rather than absolute deviations. If we do that, we obtain a measure is called the <strong><em>variance</em></strong>, which has a lot of really nice statistical properties that I’m going to ignore <a class="footnote-reference brackets" href="#variance1" id="id3">1</a>, and one massive psychological flaw that I’m going to make a big deal out of in a moment. The variance of a data set <span class="math notranslate nohighlight">\(X\)</span> is sometimes written as <span class="math notranslate nohighlight">\(\mbox{Var}(X)\)</span>, but it’s more commonly denoted <span class="math notranslate nohighlight">\(s^2\)</span> (the reason for this will become clearer shortly). The formula that we use to calculate the variance of a set of observations is as follows:</p>
<p><span class="math notranslate nohighlight">\(\mbox{Var}(X) = \frac{1}{N} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2\)</span></p>
<p><span class="math notranslate nohighlight">\(\mbox{Var}(X) = \frac{\sum_{i=1}^N \left( X_i - \bar{X} \right)^2}{N}\)</span></p>
<p>The variance is sometimes referred to as the “mean square deviation” because it, well, is the average of the squared deviations from the mean.</p>
<p>As you might expect by now computing the variance is quite simple in Pandas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1016.1205186065329
</pre></div>
</div>
</div>
</div>
<p>We can double check this is the right formula by hand taking advantage of the ability of Pandas columns to “broadcast” over integers (see <a class="reference external" href="../../chapters/05/00-data.html#arithmetic">here</a> for a reminder):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1016.0016741014326
</pre></div>
</div>
</div>
</div>
<p>Oh, weird the numbers are not exactly the same!  What happened?  The reason is that Panda’s <code class="docutils literal notranslate"><span class="pre">.var()</span></code> function gives you the <strong>sample variance</strong> by default which computes the formula for variance like this:</p>
<p><span class="math notranslate nohighlight">\(\mbox{Var}(X) = \frac{\sum_{i=1}^N \left( X_i - \bar{X} \right)^2}{N-1}\)</span></p>
<p>We can force it to use the other formula by manually setting an argument <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1016.0016741014326
</pre></div>
</div>
</div>
</div>
<p>Read more about the arguments to <code class="docutils literal notranslate"><span class="pre">.var()</span></code> <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.var.html">here</a>.</p>
<p>So <em>why</em> Python is dividing by <span class="math notranslate nohighlight">\(N-1\)</span> and not by <span class="math notranslate nohighlight">\(N\)</span>. After all, the variance is supposed to be the <em>mean</em> squared deviation, right? So shouldn’t we be dividing by <span class="math notranslate nohighlight">\(N\)</span>, the actual number of observations in the sample? Well, yes, we should. However, as we’ll discuss in an <span class="xref myst">upcoming chapter</span>, there’s a subtle distinction between “describing a sample” and “making guesses about the population from which the sample came”. Up to this point, it’s been a distinction without a difference. Regardless of whether you’re describing a sample or drawing inferences about the population, the mean is calculated exactly the same way. Not so for the variance, or the standard deviation, or for many other measures besides. What I outlined to you initially (i.e., take the actual average, and thus divide by <span class="math notranslate nohighlight">\(N\)</span>) assumes that you literally intend to calculate the variance of the sample. Most of the time, however, you’re not terribly interested in the sample <em>in and of itself</em>. Rather, the sample exists to tell you something about the world. If so, you’re actually starting to move away from calculating a “sample statistic”, and towards the idea of estimating a “population parameter”.</p>
<p>Okay, one last thing. This section so far has read a bit like a mystery novel. I’ve shown you how to calculate the variance, described the weird “<span class="math notranslate nohighlight">\(N-1\)</span>” thing that Pandas does and hinted at the reason why it’s there, but I haven’t mentioned the single most important thing… how do you <em>interpret</em> the variance? Descriptive statistics are supposed to describe things, after all, and right now the variance is really just a gibberish number. Unfortunately, the reason why I haven’t given you the human-friendly interpretation of the variance is that there really isn’t one. This is the most serious problem with the variance. Although it has some elegant mathematical properties that suggest that it really is a fundamental quantity for expressing variation, it’s completely useless if you want to communicate with an actual human… variances are completely uninterpretable in terms of the original variable! All the numbers have been squared, and they don’t mean anything anymore. This is a huge issue. For instance, according to the table I presented earlier, the margin in game 1 was “376.36 points-squared higher than the average margin”. This is <em>exactly</em> as stupid as it sounds; and so when we calculate a variance of 324.64, we’re in the same situation. I’ve watched a lot of footy games, and never has anyone referred to “points squared”. It’s <em>not</em> a real unit of measurement, and since the variance is expressed in terms of this gibberish unit, it is totally meaningless to a human.</p>
</div>
<div class="section" id="standard-deviation">
<h3><span class="section-number">8.3.4. </span>Standard deviation<a class="headerlink" href="#standard-deviation" title="Permalink to this headline">¶</a></h3>
<p>Okay, suppose that you like the idea of using the variance because of those nice mathematical properties that I haven’t talked about, but – since you’re a human and not a robot – you’d like to have a measure that is expressed in the same units as the data itself (i.e., points, not points-squared). What should you do? The solution to the problem is obvious: take the square root of the variance, known as the <strong><em>standard deviation</em></strong>, also called the “root mean squared deviation”, or RMSD. This solves our problem fairly neatly: while nobody has a clue what “a variance of 324.68 points-squared” really means, it’s much easier to understand “a standard deviation of 18.01 points”, since it’s expressed in the original units. It is traditional to refer to the standard deviation of a sample of data as <span class="math notranslate nohighlight">\(s\)</span>, though “sd” and “std dev.” are also used at times. Because the standard deviation is equal to the square root of the variance, you probably won’t be surprised to see that the formula is:</p>
<p><span class="math notranslate nohighlight">\(s = \sqrt{ \frac{1}{N} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2 }\)</span></p>
<p>and the Python function that we use to calculate it is <code class="docutils literal notranslate"><span class="pre">std()</span></code>. However, as you might have guessed from our discussion of the variance, what Python actually calculates is slightly different to the formula given above. Just like the we saw with the variance, what Python calculates is a version that divides by <span class="math notranslate nohighlight">\(N-1\)</span> rather than <span class="math notranslate nohighlight">\(N\)</span>:
$<span class="math notranslate nohighlight">\(
\hat\sigma = \sqrt{ \frac{1}{N-1} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2 }
\)</span>$
With that in mind, calculating standard deviations in Python is again simple:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>31.876645347441013
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">())</span> <span class="c1"># notice same value!</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>31.876645347441013
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="which-measure-to-use">
<h3><span class="section-number">8.3.5. </span>Which measure to use?<a class="headerlink" href="#which-measure-to-use" title="Permalink to this headline">¶</a></h3>
<p>We’ve discussed quite a few measures of spread (range, IQR, variance and standard deviation), and hinted at their strengths and weaknesses. Here’s a quick summary:</p>
<ul class="simple">
<li><p><em>Range</em>. Gives you the full spread of the data. It’s very vulnerable to outliers, and as a consequence it isn’t often used unless you have good reasons to care about the extremes in the data.</p></li>
<li><p><em>Interquartile range</em>. Tells you where the “middle half” of the data sits. It’s pretty robust, and complements the median nicely. This is used a lot.</p></li>
<li><p><em>Variance</em>. Tells you the average squared deviation from the mean. It’s mathematically elegant, and is probably the “right” way to describe variation around the mean, but it’s completely uninterpretable because it doesn’t use the same units as the data. Almost never used except as a mathematical tool; but it’s buried “under the hood” of a very large number of statistical tools.</p></li>
<li><p><em>Standard deviation</em>. This is the square root of the variance. It’s fairly elegant mathematically, and it’s expressed in the same units as the data so it can be interpreted pretty well. In situations where the mean is the measure of central tendency, this is the default. This is by far the most popular measure of variation.</p></li>
</ul>
<p>In short, the IQR and the standard deviation are easily the two most common measures used to report the variability of the data; but there are situations in which the others are used. I’ve described a few of them in this book because there’s a fair chance you’ll run into most of these somewhere.</p>
</div>
</div>
<div class="section" id="remember-to-look-at-your-data">
<h2><span class="section-number">8.4. </span>Remember to look at your data<a class="headerlink" href="#remember-to-look-at-your-data" title="Permalink to this headline">¶</a></h2>
<p>Descriptive statistics are great and we will use them a lot in the course to describe data. You may suspect that descriptive statistics also have some short-comings. This is very true. They are compressed summaries of large piles of numbers. They will almost always be unable to represent all of the numbers fairly. There are also different kinds of descriptive statistics that you could use, and it sometimes not clear which one’s you should use.</p>
<p>Perhaps the most important thing you can do when using descriptives is to use them in combination with looking at the data in a graph form (i.e., <span class="xref myst">visualization</span>). This can help you see whether or not your descriptives are doing a good job of representing the data.  For instance remember the discussion from the previous chapter on <a class="reference external" href="../../chapters/06/00-plots.html#why-create-visualizations">Anscombe’s Quartet</a> where we were arguing that visualization provide an important check on the validity of various quantitative summaries of data <span id="id4">[<a class="reference internal" href="#id93">Anscombe, 1973</a>]</span>.  It is up to you to check that your descriptive statistics reflect the data in a faithful way.  What you might typically do in an analysis is compute descriptive statistics, plot your data, and then so long as everything seems reasonable report only the descriptive statistics in the paper except for the key/most important findings.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you thought that Anscombe’s quartet was neat, you should take a look at the <a class="reference external" href="https://www.autodeskresearch.com/publications/samestats">Datasaurus Dozen</a> <span id="id5">[<a class="reference internal" href="#id60">Matejka and Fitzmaurice, 2017</a>]</span>. Scroll down to see the examples. You will be looking at dot plots. The dot plots show many different patterns, including dinosaurs! What’s amazing is that all of the dots have very nearly the same descriptive statistics. Just another reminder to look at your data, it might look like a dinosaur!</p>
</div>
</div>
<div class="section" id="summarizing-at-different-levels">
<h2><span class="section-number">8.5. </span>Summarizing at different levels<a class="headerlink" href="#summarizing-at-different-levels" title="Permalink to this headline">¶</a></h2>
<p>So far we have mostly examined how to apply descriptive statistics to the entire column of a dataframe.  However, often we want to apply descriptive statistics to smaller groups of data.  For instance consider the <code class="docutils literal notranslate"><span class="pre">recall_accuracy</span></code> column of the OMNI dataset we have been exploring in this chapter.  This is a 0/1 column coding if the person got a particular word correct at test.  Although we could computed the <code class="docutils literal notranslate"><span class="pre">.mean()</span></code> on this column to find the average accuracy of the entire group of subjects there are several reasons we might not find that as useful.  First is that there are different participants in the dataset and we might be interested in the range of individual performances in the task.  In addition, there was an experimental condition: delay between study and test.  If you compute the mean of the entire <code class="docutils literal notranslate"><span class="pre">recall_accuracy</span></code> column, we will be obscuring how study-test delay might be influencing performance by putting all the data into one summary.</p>
<p>For this reason is it often that we want to apply descriptive statistics to sub-groups of data and then submit these values to further inspection, visualization, description, and analysis.  To do this we will combine a bit of what we learned in the previous chapter on the <a class="reference external" href="../../chapters/05/00-data.html#the-split-apply-combine-workflow">Split-apply-combine</a> workflow with the information we gained in this chapter about descriptive statistics.</p>
<p>For instance, let’s say we are interested in average memory performance as a function of the delay condition the subjects were in.  One simple way to do this is using <code class="docutils literal notranslate"><span class="pre">.groupby()</span></code> to first group based on condition then to “apply” the mean function to each group:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;delay_group&quot;</span><span class="p">)[</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>delay_group
A          0.613333
C          0.524263
E          0.222222
F          0.424444
H          0.248980
PRISMAF    0.373545
Name: recall_accuracy, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>This command does quite a lot so maybe we should step through it.  The first thing to recognize is that this command combines several steps using <strong>chaining</strong> where multiuple methods are computed in a sequence in a single line strung together by dots (<code class="docutils literal notranslate"><span class="pre">.</span></code>).  The first step does a <code class="docutils literal notranslate"><span class="pre">.groupby()</span></code> on the <code class="docutils literal notranslate"><span class="pre">delay_group</span></code> column.  If you remember from our earlier discussion of grouping this will form groups where each group contains all the rows that share the same value on the <code class="docutils literal notranslate"><span class="pre">delay_group</span></code> column (meaning were in the same condition).  Next you see the column indexing operation <code class="docutils literal notranslate"><span class="pre">['recall_accuracy']</span></code> which means we just pulled out the accuracy column.  Then we use <code class="docutils literal notranslate"><span class="pre">.mean()</span></code> to summarize the groups.  This results not in one mean but serveral, one for each group.  As we can see performance was highest in the A group which was the immediate test condition.  Performance was low (~23%) in the E and H groups which were 48 hours or more of delay.</p>
<p>We can easily reorganize this for different analyses.  For instance imagine we want to focus on group A but find how hard different words were.  For this we first select the A group then group by the word pair:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;delay_group&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;lith_word_studied&quot;</span><span class="p">)[</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lith_word_studied
akis         0.90
arbata       0.95
batas        0.70
bugnas       0.65
burna        0.70
daina        0.60
dirzas       0.50
duona        0.65
gelezis      0.40
kamuolys     0.40
karalius     0.50
kardas       0.45
kirvis       0.20
knyga        0.70
kreida       0.55
kriaukle     0.35
kumpis       0.55
kunigas      0.50
laikrodis    0.50
laiptelis    0.45
lietus       0.45
lova         1.00
masina       0.55
mesa         0.95
miestas      0.50
mokykla      0.80
muilas       0.70
nafta        0.80
padazas      0.20
pastatas     0.90
pinigine     0.30
plyta        0.55
pupa         0.85
purvas       0.60
rusys        0.75
sausainis    0.75
sesuo        0.90
smegenys     0.70
smuikas      0.25
tiltas       0.75
traukinys    0.90
upe          0.85
vaistas      0.30
varpas       0.15
zele         0.95
Name: recall_accuracy, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>In this analysis, we get a much longer list which shows the recall accuracy for each word pair in the experiment.</p>
<p>We can also group by multiple factors to see how word difficulty changes across the different conditions rather than focusing only on group A:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;delay_group&quot;</span><span class="p">,</span><span class="s2">&quot;lith_word_studied&quot;</span><span class="p">])[</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>delay_group  lith_word_studied
A            akis                 0.900000
             arbata               0.950000
             batas                0.700000
             bugnas               0.650000
             burna                0.700000
                                    ...   
PRISMAF      traukinys            0.380952
             upe                  0.380952
             vaistas              0.238095
             varpas               0.238095
             zele                 0.428571
Name: recall_accuracy, Length: 270, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The output for this one is too long, but we can do a few minor transformations of the data (using <code class="docutils literal notranslate"><span class="pre">.unstack()</span></code> to get rid of the heirarchical index, and <code class="docutils literal notranslate"><span class="pre">.transpose()</span></code> to swap the rows and columns), which gives us a nicer view of how each word varies across condition.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;delay_group&quot;</span><span class="p">,</span><span class="s2">&quot;lith_word_studied&quot;</span><span class="p">])[</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>delay_group</th>
      <th>A</th>
      <th>C</th>
      <th>E</th>
      <th>F</th>
      <th>H</th>
      <th>PRISMAF</th>
    </tr>
    <tr>
      <th>lith_word_studied</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>akis</th>
      <td>0.90</td>
      <td>0.714286</td>
      <td>0.0</td>
      <td>0.58</td>
      <td>0.306122</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>arbata</th>
      <td>0.95</td>
      <td>0.591837</td>
      <td>0.0</td>
      <td>0.44</td>
      <td>0.204082</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>batas</th>
      <td>0.70</td>
      <td>0.530612</td>
      <td>0.0</td>
      <td>0.34</td>
      <td>0.346939</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>bugnas</th>
      <td>0.65</td>
      <td>0.510204</td>
      <td>1.0</td>
      <td>0.50</td>
      <td>0.244898</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>burna</th>
      <td>0.70</td>
      <td>0.632653</td>
      <td>0.0</td>
      <td>0.54</td>
      <td>0.204082</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>daina</th>
      <td>0.60</td>
      <td>0.591837</td>
      <td>0.0</td>
      <td>0.46</td>
      <td>0.387755</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>dirzas</th>
      <td>0.50</td>
      <td>0.367347</td>
      <td>0.0</td>
      <td>0.30</td>
      <td>0.183673</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>duona</th>
      <td>0.65</td>
      <td>0.530612</td>
      <td>0.0</td>
      <td>0.42</td>
      <td>0.244898</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>gelezis</th>
      <td>0.40</td>
      <td>0.408163</td>
      <td>0.0</td>
      <td>0.24</td>
      <td>0.122449</td>
      <td>0.285714</td>
    </tr>
    <tr>
      <th>kamuolys</th>
      <td>0.40</td>
      <td>0.367347</td>
      <td>0.0</td>
      <td>0.20</td>
      <td>0.061224</td>
      <td>0.190476</td>
    </tr>
    <tr>
      <th>karalius</th>
      <td>0.50</td>
      <td>0.551020</td>
      <td>1.0</td>
      <td>0.52</td>
      <td>0.285714</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>kardas</th>
      <td>0.45</td>
      <td>0.428571</td>
      <td>1.0</td>
      <td>0.34</td>
      <td>0.265306</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>kirvis</th>
      <td>0.20</td>
      <td>0.408163</td>
      <td>0.0</td>
      <td>0.26</td>
      <td>0.204082</td>
      <td>0.190476</td>
    </tr>
    <tr>
      <th>knyga</th>
      <td>0.70</td>
      <td>0.489796</td>
      <td>0.0</td>
      <td>0.36</td>
      <td>0.244898</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>kreida</th>
      <td>0.55</td>
      <td>0.408163</td>
      <td>1.0</td>
      <td>0.32</td>
      <td>0.306122</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>kriaukle</th>
      <td>0.35</td>
      <td>0.265306</td>
      <td>1.0</td>
      <td>0.16</td>
      <td>0.081633</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>kumpis</th>
      <td>0.55</td>
      <td>0.346939</td>
      <td>0.0</td>
      <td>0.28</td>
      <td>0.122449</td>
      <td>0.190476</td>
    </tr>
    <tr>
      <th>kunigas</th>
      <td>0.50</td>
      <td>0.387755</td>
      <td>0.0</td>
      <td>0.34</td>
      <td>0.224490</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>laikrodis</th>
      <td>0.50</td>
      <td>0.265306</td>
      <td>0.0</td>
      <td>0.18</td>
      <td>0.142857</td>
      <td>0.190476</td>
    </tr>
    <tr>
      <th>laiptelis</th>
      <td>0.45</td>
      <td>0.265306</td>
      <td>0.0</td>
      <td>0.34</td>
      <td>0.122449</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>lietus</th>
      <td>0.45</td>
      <td>0.326531</td>
      <td>0.0</td>
      <td>0.42</td>
      <td>0.122449</td>
      <td>0.285714</td>
    </tr>
    <tr>
      <th>lova</th>
      <td>1.00</td>
      <td>0.857143</td>
      <td>0.0</td>
      <td>0.70</td>
      <td>0.489796</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>masina</th>
      <td>0.55</td>
      <td>0.448980</td>
      <td>0.0</td>
      <td>0.44</td>
      <td>0.142857</td>
      <td>0.380952</td>
    </tr>
    <tr>
      <th>mesa</th>
      <td>0.95</td>
      <td>0.918367</td>
      <td>1.0</td>
      <td>0.82</td>
      <td>0.653061</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>miestas</th>
      <td>0.50</td>
      <td>0.530612</td>
      <td>0.0</td>
      <td>0.34</td>
      <td>0.265306</td>
      <td>0.285714</td>
    </tr>
    <tr>
      <th>mokykla</th>
      <td>0.80</td>
      <td>0.693878</td>
      <td>0.0</td>
      <td>0.60</td>
      <td>0.387755</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <th>muilas</th>
      <td>0.70</td>
      <td>0.469388</td>
      <td>0.0</td>
      <td>0.28</td>
      <td>0.183673</td>
      <td>0.285714</td>
    </tr>
    <tr>
      <th>nafta</th>
      <td>0.80</td>
      <td>0.693878</td>
      <td>1.0</td>
      <td>0.64</td>
      <td>0.428571</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <th>padazas</th>
      <td>0.20</td>
      <td>0.306122</td>
      <td>0.0</td>
      <td>0.18</td>
      <td>0.040816</td>
      <td>0.142857</td>
    </tr>
    <tr>
      <th>pastatas</th>
      <td>0.90</td>
      <td>0.795918</td>
      <td>1.0</td>
      <td>0.74</td>
      <td>0.510204</td>
      <td>0.571429</td>
    </tr>
    <tr>
      <th>pinigine</th>
      <td>0.30</td>
      <td>0.469388</td>
      <td>0.0</td>
      <td>0.32</td>
      <td>0.061224</td>
      <td>0.142857</td>
    </tr>
    <tr>
      <th>plyta</th>
      <td>0.55</td>
      <td>0.367347</td>
      <td>0.0</td>
      <td>0.26</td>
      <td>0.163265</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>pupa</th>
      <td>0.85</td>
      <td>0.734694</td>
      <td>1.0</td>
      <td>0.66</td>
      <td>0.346939</td>
      <td>0.761905</td>
    </tr>
    <tr>
      <th>purvas</th>
      <td>0.60</td>
      <td>0.591837</td>
      <td>0.0</td>
      <td>0.42</td>
      <td>0.265306</td>
      <td>0.476190</td>
    </tr>
    <tr>
      <th>rusys</th>
      <td>0.75</td>
      <td>0.591837</td>
      <td>0.0</td>
      <td>0.46</td>
      <td>0.163265</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>sausainis</th>
      <td>0.75</td>
      <td>0.632653</td>
      <td>0.0</td>
      <td>0.50</td>
      <td>0.306122</td>
      <td>0.380952</td>
    </tr>
    <tr>
      <th>sesuo</th>
      <td>0.90</td>
      <td>0.795918</td>
      <td>0.0</td>
      <td>0.60</td>
      <td>0.428571</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <th>smegenys</th>
      <td>0.70</td>
      <td>0.653061</td>
      <td>0.0</td>
      <td>0.50</td>
      <td>0.265306</td>
      <td>0.476190</td>
    </tr>
    <tr>
      <th>smuikas</th>
      <td>0.25</td>
      <td>0.326531</td>
      <td>0.0</td>
      <td>0.14</td>
      <td>0.163265</td>
      <td>0.380952</td>
    </tr>
    <tr>
      <th>tiltas</th>
      <td>0.75</td>
      <td>0.530612</td>
      <td>0.0</td>
      <td>0.54</td>
      <td>0.306122</td>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>traukinys</th>
      <td>0.90</td>
      <td>0.714286</td>
      <td>0.0</td>
      <td>0.62</td>
      <td>0.285714</td>
      <td>0.380952</td>
    </tr>
    <tr>
      <th>upe</th>
      <td>0.85</td>
      <td>0.693878</td>
      <td>0.0</td>
      <td>0.52</td>
      <td>0.306122</td>
      <td>0.380952</td>
    </tr>
    <tr>
      <th>vaistas</th>
      <td>0.30</td>
      <td>0.387755</td>
      <td>0.0</td>
      <td>0.38</td>
      <td>0.061224</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>varpas</th>
      <td>0.15</td>
      <td>0.204082</td>
      <td>1.0</td>
      <td>0.14</td>
      <td>0.122449</td>
      <td>0.238095</td>
    </tr>
    <tr>
      <th>zele</th>
      <td>0.95</td>
      <td>0.795918</td>
      <td>0.0</td>
      <td>0.76</td>
      <td>0.428571</td>
      <td>0.428571</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Of course, one of the most important transformation is to find the accuracy per-subject (since subjects are often our unit of analysis).  In this case we might like to compute the average performance of each person but copy over several of the other attributes such as the condition.  For this we are going to use a more complex command called <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#named-aggregation">named aggregation</a> which results in a new dataframe that is “tidy” in the sense of each row being an observation (person) and each column being a descriptor or variable but we got rid of the individual trials here and replaced them with the average across the trials.  This is a very common type of step in behavior data analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;participant_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">delay_group</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">NamedAgg</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;delay_group&#39;</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">),</span>
                                 <span class="n">recall_accuracy</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">NamedAgg</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>participant_id</th>
      <th>delay_group</th>
      <th>recall_accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A1</td>
      <td>A</td>
      <td>0.644444</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A10</td>
      <td>A</td>
      <td>0.555556</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A11</td>
      <td>A</td>
      <td>0.444444</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A12</td>
      <td>A</td>
      <td>0.955556</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A13</td>
      <td>A</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>185</th>
      <td>PRISMAF28</td>
      <td>PRISMAF</td>
      <td>0.244444</td>
    </tr>
    <tr>
      <th>186</th>
      <td>PRISMAF29</td>
      <td>PRISMAF</td>
      <td>0.644444</td>
    </tr>
    <tr>
      <th>187</th>
      <td>PRISMAF30</td>
      <td>PRISMAF</td>
      <td>0.866667</td>
    </tr>
    <tr>
      <th>188</th>
      <td>PRISMAF31</td>
      <td>PRISMAF</td>
      <td>0.511111</td>
    </tr>
    <tr>
      <th>189</th>
      <td>PRISMAF32</td>
      <td>PRISMAF</td>
      <td>0.222222</td>
    </tr>
  </tbody>
</table>
<p>190 rows × 3 columns</p>
</div></div></div>
</div>
<p>Explaining all the ins and out of aggregating descriptive statistics is beyond the scope here.  In reality is it something you have to kind of wrestle with sometimes when working with data.  However, hopefully knowledge about a few of these commands and the general operations available to you can help you think forward about how best to design a data transformation for your problem.</p>
</div>
<div class="section" id="creating-your-own-custom-descriptive-statistics">
<h2><span class="section-number">8.6. </span>Creating your own custom descriptive statistics<a class="headerlink" href="#creating-your-own-custom-descriptive-statistics" title="Permalink to this headline">¶</a></h2>
<p>In addition to the standard statistics like mean, median, variance, etc… it is possible to compute custom descriptive statistics on your data.  This sometimes comes up in the context of a psychology experiment where something like “proportion of learning blocks where people reached some criterion” might be your statistic.  In those cases you might need to write a custom definition of a statistic and apply it to your data.</p>
<p>One way to do this in Pandas is with the <code class="docutils literal notranslate"><span class="pre">.apply()</span></code> function (docs <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#flexible-apply">here</a>).  Let’s look at an example by using <code class="docutils literal notranslate"><span class="pre">.apply()</span></code> to compute a custom variation measure called the mean absolute deviation.  This is related to the mean squared deviation used in the normal variance but instead of squaring the numbers we take their absolute value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_absolute_deviation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;participant_id&#39;</span><span class="p">)[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">mean_absolute_deviation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>participant_id
A1           13.556543
A10          25.723457
A11          16.192593
A12           4.933333
A13          20.847407
               ...    
PRISMAF28    23.782716
PRISMAF29    18.267654
PRISMAF30    21.901235
PRISMAF31    10.641975
PRISMAF32    23.976296
Name: jol_value, Length: 190, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>In this cell we defined a new function which takes as input a vector of data <code class="docutils literal notranslate"><span class="pre">x</span></code> and the computes the mean absolute deviation using Numpy functions (e.g., <code class="docutils literal notranslate"><span class="pre">np.abs</span></code> is the absolute value, and <code class="docutils literal notranslate"><span class="pre">np.mean</span></code> is another function for computing a mean).  Then we grouped the data by <code class="docutils literal notranslate"><span class="pre">participant_id</span></code>, selected the <code class="docutils literal notranslate"><span class="pre">jol_value</span></code> column and <code class="docutils literal notranslate"><span class="pre">.apply()</span></code> the custom function we wrote.</p>
</div>
<div class="section" id="correlations-and-covariance">
<h2><span class="section-number">8.7. </span>Correlations and Covariance<a class="headerlink" href="#correlations-and-covariance" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>“Correlation does not equal causation.” —Every statistics and research methods instructor ever</p>
</div></blockquote>
<p>Up to this point we have focused entirely on how to construct descriptive statistics for a single variable. What we haven’t done is talked about how to describe the relationships <em>between</em> variables in the data. To do that, we want to talk mostly about the <strong><em>correlation</em></strong> between variables. This is also a descriptive statistic in the traditional definition, but here described the relationship between two variables rather than summarizing the properties of just a single variable.</p>
<div class="section" id="the-strength-and-direction-of-a-relationship">
<h3><span class="section-number">8.7.1. </span>The strength and direction of a relationship<a class="headerlink" href="#the-strength-and-direction-of-a-relationship" title="Permalink to this headline">¶</a></h3>
<p>We can draw scatterplots to give us a general sense of how closely related two variables are. For example, we can first you the split-apply-combine workflow to organize the data into the average JOL and average recall accuracy for each word and store this in a new dataframe:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_df</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;lith_word_studied&quot;</span><span class="p">)[[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">,</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;jol_value&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">corr_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12b7444a8&gt;
</pre></div>
</div>
<img alt="../../_images/00-describingdata_84_1.png" src="../../_images/00-describingdata_84_1.png" />
</div>
</div>
<p>This scatter plot shows that the average JOL rating seems to be related to recall accuracy such that higher JOL ratings were given to word that were more accurately remembered.  This suggests that people have some reasonably calibrated “meta-cognition” about how well they learned something.  What is your JOL for the material in this chapter?</p>
</div>
<div class="section" id="the-correlation-coefficient">
<h3><span class="section-number">8.7.2. </span>The correlation coefficient<a class="headerlink" href="#the-correlation-coefficient" title="Permalink to this headline">¶</a></h3>
<p>We can make these ideas a bit more explicit by introducing the idea of a <strong><em>correlation coefficient</em></strong> (or, more specifically, Pearson’s correlation coefficient), which is traditionally denoted by <span class="math notranslate nohighlight">\(r\)</span>. The correlation coefficient between two variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> (sometimes denoted <span class="math notranslate nohighlight">\(r_{XY}\)</span>), which we’ll define more precisely in the next section, is a measure that varies from <span class="math notranslate nohighlight">\(-1\)</span> to <span class="math notranslate nohighlight">\(1\)</span>. When <span class="math notranslate nohighlight">\(r = -1\)</span> it means that we have a perfect negative relationship, and when <span class="math notranslate nohighlight">\(r = 1\)</span> it means we have a perfect positive relationship. When <span class="math notranslate nohighlight">\(r = 0\)</span>, there’s no relationship at all. If you look at <a class="reference internal" href="#fig-corr"><span class="std std-numref">Fig. 8.2</span></a>, you can see several plots showing what different correlations look like.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span><span class="n">sharex</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.33</span><span class="p">,</span><span class="o">-</span><span class="mf">0.33</span><span class="p">,</span><span class="mf">0.66</span><span class="p">,</span><span class="o">-</span><span class="mf">0.66</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">npr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="n">cor</span><span class="p">],[</span><span class="n">cor</span><span class="p">,</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>  <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;r = </span><span class="si">{</span><span class="n">cor</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;cor_fig&quot;</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/00-describingdata_87_1.png" src="../../_images/00-describingdata_87_1.png" />
</div>
</div>
<div class="figure align-default" id="fig-corr" style="width: 400px">
<div class="cell_output docutils container">
<img alt="../../_images/00-describingdata_87_0.png" src="../../_images/00-describingdata_87_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 8.2 </span><span class="caption-text">Illustration of the effect of varying the strength and direction of a correlation</span><a class="headerlink" href="#fig-corr" title="Permalink to this image">¶</a></p>
</div>
<p>The formula for the Pearson’s correlation coefficient can be written in several different ways. I think the simplest way to write down the formula is to break it into two steps. Firstly, let’s introduce the idea of a <strong><em>covariance</em></strong>. The covariance between two variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is a generalization of the notion of the variance; it’s a mathematically simple way of describing the relationship between two variables that isn’t terribly informative to humans:</p>
<p><span class="math notranslate nohighlight">\(
\mbox{Cov}(X,Y) = \frac{1}{N-1} \sum_{i=1}^N \left( X_i - \bar{X} \right) \left( Y_i - \bar{Y} \right)
\)</span></p>
<p>Because we’re multiplying (i.e., taking the “product” of) a quantity that depends on <span class="math notranslate nohighlight">\(X\)</span> by a quantity that depends on <span class="math notranslate nohighlight">\(Y\)</span> and then averaging <a class="footnote-reference brackets" href="#covariance" id="id6">2</a>, you can think of the formula for the covariance as an “average cross product” between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. The covariance has the nice property that, if <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are entirely unrelated, then the covariance is exactly zero. If the relationship between them is positive (in the sense shown in <a class="reference internal" href="#fig-corr"><span class="std std-numref">Fig. 8.2</span></a>) then the covariance is also positive; and if the relationship is negative then the covariance is also negative. In other words, the covariance captures the basic qualitative idea of correlation. Unfortunately, the raw magnitude of the covariance isn’t easy to interpret: it depends on the units in which <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are expressed, and worse yet, the actual units that the covariance itself is expressed in are really weird. For instance, if <span class="math notranslate nohighlight">\(X\)</span> refers to the <code class="docutils literal notranslate"><span class="pre">jol_value</span></code> variable (units: rating points on a judgement) and <span class="math notranslate nohighlight">\(Y\)</span> refers to the <code class="docutils literal notranslate"><span class="pre">recall_accuracy</span></code> variable (units: proportion accurate), then the units for their covariance are “rating points <span class="math notranslate nohighlight">\(\times\)</span> accuracy”. And I have no freaking idea what that would even mean.</p>
<p>The Pearson correlation coefficient <span class="math notranslate nohighlight">\(r\)</span> fixes this interpretation problem by standardizing the covariance, in pretty much the exact same way that the <span class="math notranslate nohighlight">\(z\)</span>-score standardizes a raw score: by dividing by the standard deviation. However, because we have two variables that contribute to the covariance, the standardization only works if we divide by both standard deviations <a class="footnote-reference brackets" href="#corsimple" id="id7">3</a>.  In other words, the correlation between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> can be written as follows:</p>
<p><span class="math notranslate nohighlight">\(
r_{XY}  = \frac{\mbox{Cov}(X,Y)}{ \hat{\sigma}_X \ \hat{\sigma}_Y}
\)</span></p>
<p>By doing this standardization, not only do we keep all of the nice properties of the covariance discussed earlier, but the actual values of <span class="math notranslate nohighlight">\(r\)</span> are on a meaningful scale: <span class="math notranslate nohighlight">\(r= 1\)</span> implies a perfect positive relationship, and <span class="math notranslate nohighlight">\(r = -1\)</span> implies a perfect negative relationship. I’ll expand a little more on this point later. But before I do, let’s look at how to calculate correlations in R.</p>
</div>
<div class="section" id="calculating-correlations-in-python">
<h3><span class="section-number">8.7.3. </span>Calculating correlations in Python<a class="headerlink" href="#calculating-correlations-in-python" title="Permalink to this headline">¶</a></h3>
<p>There are several methods for computing the correlation coefficient in Python including using <a class="reference external" href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html">Scipy</a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html">Numpy</a>, and <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html">Pandas</a>.</p>
<p>Usually one is interested in just the regular correlation coefficient, <span class="math notranslate nohighlight">\(r\)</span>, which is easy to do with Scipy’s <code class="docutils literal notranslate"><span class="pre">pearsonr</span></code> command:</p>
<p>You simply specify the vector of numbers to use as x and y and the function returns a tuple. The first is the pearson <span class="math notranslate nohighlight">\(r\)</span> value and the second is the <span class="math notranslate nohighlight">\(p\)</span>-value from a hypothesis test that the correlation coefficient is greater than 0 (a future chapter will go more deeply into the logic of hypothesis testing).</p>
<p>However, there is also a <code class="docutils literal notranslate"><span class="pre">corr()</span></code> function available as a dataframe method in Pandsa that is a bit more powerful than this simple example suggests. For example, you can also calculate a complete “correlation matrix”, between all pairs of variables in the data frame:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span> <span class="n">x</span> <span class="o">=</span> <span class="n">corr_df</span><span class="p">[</span><span class="s1">&#39;jol_value&#39;</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">corr_df</span><span class="p">[</span><span class="s1">&#39;recall_accuracy&#39;</span><span class="p">]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.9274668603778027, 5.528157257418477e-20)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>jol_value</th>
      <th>recall_accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>jol_value</th>
      <td>1.000000</td>
      <td>0.927467</td>
    </tr>
    <tr>
      <th>recall_accuracy</th>
      <td>0.927467</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="interpreting-a-correlation">
<h3><span class="section-number">8.7.4. </span>Interpreting a correlation<a class="headerlink" href="#interpreting-a-correlation" title="Permalink to this headline">¶</a></h3>
<p>Naturally, in real life you don’t see many correlations of 1. So how should you interpret a correlation of, say <span class="math notranslate nohighlight">\(r= .4\)</span>? The honest answer is that it really depends on what you want to use the data for, and on how strong the correlations in your field tend to be. A friend of mine in engineering once argued that any correlation less than <span class="math notranslate nohighlight">\(.95\)</span> is completely useless (I think he was exaggerating, even for engineering). On the other hand there are real cases – even in psychology – where you should really expect correlations that strong. For instance, one of the benchmark data sets used to test theories of how people judge similarities is so clean that any theory that can’t achieve a correlation of at least <span class="math notranslate nohighlight">\(.9\)</span> really isn’t deemed to be successful. However, when looking for (say) elementary correlates of intelligence (e.g., inspection time, response time), if you get a correlation above <span class="math notranslate nohighlight">\(.3\)</span> you’re doing very very well. In short, the interpretation of a correlation depends a lot on the context.</p>
<p>However, something that can never be stressed enough is that you should <em>always</em> look at the scatterplot before attaching any interpretation to the data. A correlation might not mean what you think it means (see above).</p>
</div>
<div class="section" id="spearman-s-rank-correlations">
<h3><span class="section-number">8.7.5. </span>Spearman’s rank correlations<a class="headerlink" href="#spearman-s-rank-correlations" title="Permalink to this headline">¶</a></h3>
<p>The Pearson correlation coefficient is useful for a lot of things, but it does have shortcomings. One issue in particular stands out: what it actually measures is the strength of the <em>linear</em> relationship between two variables. In other words, what it gives you is a measure of the extent to which the data all tend to fall on a single, perfectly straight line. Often, this is a pretty good approximation to what we mean when we say “relationship”, and so the Pearson correlation is a good thing to calculation. Sometimes, it isn’t.</p>
<p>One very common situation where the Pearson correlation isn’t quite the right thing to use arises when an increase in one variable <span class="math notranslate nohighlight">\(X\)</span> really is reflected in an increase in another variable <span class="math notranslate nohighlight">\(Y\)</span>, but the nature of the relationship isn’t necessarily linear. An example of this might be the relationship between effort and reward when studying for an exam. If you put in zero effort (<span class="math notranslate nohighlight">\(X\)</span>) into learning a subject, then you should expect a grade of 0% (<span class="math notranslate nohighlight">\(Y\)</span>). However, a little bit of effort will cause a <em>massive</em> improvement: just turning up to lectures means that you learn a fair bit, and if you just turn up to classes, and scribble a few things down so your grade might rise to 35%, all without a lot of effort. However, you just don’t get the same effect at the other end of the scale. As everyone knows, it takes <em>a lot</em> more effort to get a grade of 90% than it takes to get a grade of 55%. What this means is that, if I’ve got data looking at study effort and grades, there’s a pretty good chance that Pearson correlations will be misleading.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grades_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;hours&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">76</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">59</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">68</span><span class="p">],</span><span class="s1">&#39;grade&#39;</span><span class="p">:[</span><span class="mi">13</span><span class="p">,</span><span class="mi">91</span><span class="p">,</span><span class="mi">79</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">74</span><span class="p">,</span><span class="mi">47</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span><span class="mi">84</span><span class="p">,</span><span class="mi">88</span><span class="p">]})</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;hours&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;grade&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">grades_df</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;grades_fig&quot;</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/00-describingdata_95_1.png" src="../../_images/00-describingdata_95_1.png" />
</div>
</div>
<div class="figure align-default" id="fig-grades" style="width: 600px">
<div class="cell_output docutils container">
<img alt="../../_images/00-describingdata_95_0.png" src="../../_images/00-describingdata_95_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 8.3 </span><span class="caption-text">The relationship between hours worked and grade received, for a toy data set consisting of only 10 students (each circle corresponds to one student). The dashed line through the middle shows the linear relationship between the two variables. This produces a strong Pearson correlation of <span class="math notranslate nohighlight">\(r = .91\)</span>. However, the interesting thing to note here is that there’s actually a perfect monotonic relationship between the two variables: in this toy example at least, increasing the hours worked always increases the grade received, as illustrated by the solid line. This is reflected in a Spearman correlation of <span class="math notranslate nohighlight">\(rho = 1\)</span>. With such a small data set, however, it’s an open question as to which version better describes the actual relationship involved.
``</span><a class="headerlink" href="#fig-grades" title="Permalink to this image">¶</a></p>
</div>
<p>To illustrate, consider the data plotted in <a class="reference internal" href="#fig-grades"><span class="std std-numref">Fig. 8.3</span></a>, showing the relationship between hours worked and grade received for 10 students taking some class. The curious thing about this – highly fictitious – data set is that increasing your effort <em>always</em> increases your grade. It might be by a lot or it might be by a little, but increasing effort will never decrease your grade.</p>
<p>The raw data look like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grades_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hours</th>
      <th>grade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>76</td>
      <td>91</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40</td>
      <td>79</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16</td>
      <td>21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>28</td>
      <td>74</td>
    </tr>
    <tr>
      <th>6</th>
      <td>27</td>
      <td>47</td>
    </tr>
    <tr>
      <th>7</th>
      <td>59</td>
      <td>85</td>
    </tr>
    <tr>
      <th>8</th>
      <td>46</td>
      <td>84</td>
    </tr>
    <tr>
      <th>9</th>
      <td>68</td>
      <td>88</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>If we run a standard Pearson correlation, it shows a strong relationship between hours worked and grade received,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r =&quot;</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;hours&#39;</span><span class="p">],</span> <span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;grade&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>r = 0.9094019658612522
</pre></div>
</div>
</div>
</div>
<p>but this doesn’t actually capture the observation that increasing hours worked <em>always</em> increases the grade. There’s a sense here in which we want to be able to say that the correlation is <em>perfect</em> but for a somewhat different notion of what a “relationship” is. What we’re looking for is something that captures the fact that there is a perfect <strong><em>ordinal relationship</em></strong> here. That is, if student 1 works more hours than student 2, then we can guarantee that student 1 will get the better grade. That’s not what a correlation of <span class="math notranslate nohighlight">\(r = .91\)</span> says at all.</p>
<p>How should we address this? Actually, it’s really easy: if we’re looking for ordinal relationships, all we have to do is treat the data as if it were ordinal scale! So, instead of measuring effort in terms of “hours worked”, lets rank all 10 of our students in order of hours worked. That is, student 1 did the least work out of anyone (2 hours) so they get the lowest rank (rank = 1). Student 4 was the next laziest, putting in only  6 hours of work in over the whole semester, so they get the next lowest rank (rank = 2). Notice that I’m using “rank =1” to mean “low rank”. Sometimes in everyday language we talk about “rank = 1” to mean “top rank” rather than “bottom rank”. So be careful: you can rank “from smallest value to largest value” (i.e., small equals rank 1) or you can rank “from largest value to smallest value” (i.e., large equals rank 1). In this case, I’m ranking from smallest to largest, because that’s the default way that Python does it. But in real life, it’s really easy to forget which way you set things up, so you have to put a bit of effort into remembering!</p>
<p>Okay, so let’s have a look at our students when we rank them from worst to best in terms of effort and reward:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;rank_grade&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;grade&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>
<span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;rank_hours&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;hours&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>
<span class="n">grades_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hours</th>
      <th>grade</th>
      <th>rank_grade</th>
      <th>rank_hours</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>13</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>76</td>
      <td>91</td>
      <td>10.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40</td>
      <td>79</td>
      <td>6.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>14</td>
      <td>2.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16</td>
      <td>21</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>28</td>
      <td>74</td>
      <td>5.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>27</td>
      <td>47</td>
      <td>4.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>59</td>
      <td>85</td>
      <td>8.0</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>46</td>
      <td>84</td>
      <td>7.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>68</td>
      <td>88</td>
      <td>9.0</td>
      <td>9.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Hm. These two new columns are <em>identical</em>. The student who put in the most effort got the best grade, the student with the least effort got the worst grade, etc. (We used Pandas’ <code class="docutils literal notranslate"><span class="pre">.rank()</span></code> method to rank each column and assign it to a new column of the data frame.</p>
<p>As the table above shows, these two rankings are identical, so if we now correlate them we get a perfect relationship:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r =&quot;</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;rank_hours&#39;</span><span class="p">],</span> <span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;rank_grade&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>r = 1.0
</pre></div>
</div>
</div>
</div>
<p>What we’ve just re-invented is <strong><em>Spearman’s rank order correlation</em></strong>, usually denoted <span class="math notranslate nohighlight">\(\rho\)</span> to distinguish it from the Pearson correlation <span class="math notranslate nohighlight">\(r\)</span>. We can calculate Spearman’s <span class="math notranslate nohighlight">\(\rho\)</span> using Python also uses the Scipy stats library <code class="docutils literal notranslate"><span class="pre">spearmanr()</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r =&quot;</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;rank_hours&#39;</span><span class="p">],</span> <span class="n">grades_df</span><span class="p">[</span><span class="s1">&#39;rank_grade&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>r = 0.9999999999999999
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="reporting-descriptive-statistics">
<h2><span class="section-number">8.8. </span>Reporting Descriptive Statistics<a class="headerlink" href="#reporting-descriptive-statistics" title="Permalink to this headline">¶</a></h2>
<p>Reporting descriptive statistics in papers is fairly straight forward.  You just mention the numbers in the text or include a table of numbers summarizing the key results.  Let’s look at one example from one of my papers:</p>
<div class="figure align-default" id="fig-methods">
<a class="reference internal image-reference" href="../../_images/descriptivestats-methods.png"><img alt="../../_images/descriptivestats-methods.png" src="../../_images/descriptivestats-methods.png" style="width: 550px;" /></a>
<p class="caption"><span class="caption-number">Fig. 8.4 </span><span class="caption-text">Example methods/results section taken from <span id="id8">[<a class="reference internal" href="#id59">Osborn Popp and Gureckis, 2020</a>]</span>.</span><a class="headerlink" href="#fig-methods" title="Permalink to this image">¶</a></p>
</div>
<p>There are a few descriptive statistics reported in this one paragraph.  For instance <span class="math notranslate nohighlight">\(N=50\)</span> reports the number of subjects in the experiment.  Also the average duration of the task is reported using both a mean (<span class="math notranslate nohighlight">\(M=13.7\)</span> minutes) and variability (<span class="math notranslate nohighlight">\(SD=4.6\)</span>).  Typically descriptive statistics are woven into the text this way using capital letters for things like “mean” and “standard deviation” and <span class="math notranslate nohighlight">\(r\)</span> for correlation.  Here, the statistics are used just to give the reader a sense of how long the task took in general without showing a table of all the task durations for all 50 subjects (too much detail) but also more precise than the qualitative statement “about 15 minutes” which is good for intuition but also too vague by itself for a scientific report.</p>
</div>
<div class="section" id="summary">
<h2><span class="section-number">8.9. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this chapter you received a refresher on descriptive statistics and an overview of how to compute descriptive statistics using Python.  The key ideas are about being careful to choose the right descriptive statistics to summarize you data without hiding too much of the reality of the data from your audience.  In most cases, reporting descriptive statistics should go hand in hand with data visualization techniques considered in the previous chapter.</p>
</div>
<div class="section" id="references">
<h2><span class="section-number">8.10. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="id9"><dl class="citation">
<dt class="label" id="id93"><span class="brackets"><a class="fn-backref" href="#id4">Ans73</a></span></dt>
<dd><p>F. J. Anscombe. Graphs in statistical analysis. <em>American Statistician</em>, 27:17–21, 1973.</p>
</dd>
<dt class="label" id="id61"><span class="brackets"><a class="fn-backref" href="#id1">CNS19</a></span></dt>
<dd><p>M.J.C. Crump, D. Navarro, and J. Suzuki. <em>Answering Questions with Data (Textbook): Introductory Statistics for Psychology Students</em>. 2019. <a class="reference external" href="https://doi.org/https://doi.org/10.17605/OSF.IO/JZE52">doi:https://doi.org/10.17605/OSF.IO/JZE52</a>.</p>
</dd>
<dt class="label" id="id60"><span class="brackets"><a class="fn-backref" href="#id5">MF17</a></span></dt>
<dd><p>Justin Matejka and George Fitzmaurice. Same stats, different graphs: generating datasets with varied appearance and identical statistics through simulated annealing. In <em>Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</em>, 1290–1294. ACM, 2017.</p>
</dd>
<dt class="label" id="id62"><span class="brackets"><a class="fn-backref" href="#id2">Nav11</a></span></dt>
<dd><p>D. Navarro. <em>Learning Statistics with R</em>. 2011. URL: <a class="reference external" href="https://learningstatisticswithr.com">https://learningstatisticswithr.com</a>.</p>
</dd>
<dt class="label" id="id59"><span class="brackets"><a class="fn-backref" href="#id8">OPG20</a></span></dt>
<dd><p>P.J. Osborn Popp and T.M. Gureckis. Ask or tell: balancing questions and instructions in intuitive teaching. In <em>Proceedings of the 42nd Annual Conference of the Cognitive Science Society</em>. Cognitive Science Society, 2020.</p>
</dd>
</dl>
</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="variance1"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>Well, I will very briefly mention the one that I think is coolest, for a very particular definition of “cool”, that is. Variances are <em>additive</em>. Here’s what that means: suppose I have two variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, whose variances are <span class="math notranslate nohighlight">\(\mbox{Var}(X)\)</span> and <span class="math notranslate nohighlight">\(\mbox{Var}(Y)\)</span> respectively. Now imagine I want to define a new variable <span class="math notranslate nohighlight">\(Z\)</span> that is the sum of the two, <span class="math notranslate nohighlight">\(Z = X+Y\)</span>. As it turns out, the variance of <span class="math notranslate nohighlight">\(Z\)</span> is equal to <span class="math notranslate nohighlight">\(\mbox{Var}(X) + \mbox{Var}(Y)\)</span>. This is a <em>very</em> useful property, but it’s not true of the other measures that I talk about in this section.</p>
</dd>
<dt class="label" id="covariance"><span class="brackets"><a class="fn-backref" href="#id6">2</a></span></dt>
<dd><p>Just like we saw with the variance and the standard deviation, in practice we divide by <span class="math notranslate nohighlight">\(N-1\)</span> rather than <span class="math notranslate nohighlight">\(N\)</span>.</p>
</dd>
<dt class="label" id="corsimple"><span class="brackets"><a class="fn-backref" href="#id7">3</a></span></dt>
<dd><p>This is an oversimplification, but it’ll do for our purposes.</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/07"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../06/00-plots.html" title="previous page"><span class="section-number">7. </span>Visualizing Data</a>
    <a class='right-next' id="next-link" href="../08/01-sampling.html" title="next page"><span class="section-number">9. </span>Samples, populations and sampling</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Todd Gureckis<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>