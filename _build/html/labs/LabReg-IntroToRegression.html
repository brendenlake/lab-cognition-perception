
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lab 1: Introduction to Linear Regression &#8212; Lab in C&amp;P (Fall 2021)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nyustyle.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/artificialintelligence.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Lab in C&P (Fall 2021)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../course-content/syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../course-content/schedule.html">
   Schedule
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://edstem.org/us/courses/8295/discussion/">
   EdStem
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Textbook
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/00/00-cogsci.html">
   1. What is Cognitive Science and how do we study it?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/01/00-whystats.html">
   2. Why do we have to learn statistics?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/02/00-jupyter.html">
   3. Introduction to Jupyter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/03/00-python.html">
   4. Intro to Python for Psychology Undergrads
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/04/00-researchdesign.html">
   5. A brief introduction to research design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/05/00-data.html">
   6. The Format and Structure of Digital Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/06/00-plots.html">
   7. Visualizing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/07/00-describingdata.html">
   8. Describing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/08/01-sampling.html">
   9. Samples, populations and sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/09/00-hypothesistesting.html">
   10. Hypothesis testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/10/00-ttest.html">
   11. Comparing one or two means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/11/00-inferences-from-behavior.html">
   12. Measuring Behavior
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/21/00-ethics-irb.html">
   13. Research Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/13/00-linearregression.html">
   14. Linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/14/00-logisticregression.html">
   15. Logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/15/00-mixed-effect.html">
   16. Linear Mixed Effect Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/16/00-mentalsimulation.html">
   17. Mental Imagery, Mental Simulation, and Mental Rotation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/17/00-mri.html">
   18. Magnetic Resonance Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/24/00-what-next.html">
   19. What Next?
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Labs &amp; Homeworks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapters/00/cogsci-ica.html">
   Intro to CogSci ICA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../homeworks/Homework1.html">
   Intro to Jupyter (HW1)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tips &amp; Tricks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tips/pythonresources.html">
   Python Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tips/plottingresources.html">
   Plotting in Python Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tips/fortyforloops.html">
   Intro to For loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tips/nyu-jupyterhub.html">
   NYU JupyterHub Setup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tips/ultimate-guide-ttest-python.html">
   Ultimate t-test guide
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../LICENSE.html">
   License
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/labs/LabReg-IntroToRegression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://psychua-46-fall.rcnyu.org//hub/user-redirect/git-pull?repo=https://github.com/executablebooks/jupyter-book&urlpath=tree/jupyter-book/labs/LabReg-IntroToRegression.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-started-with-some-data">
   Getting started with some data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-linear-regression">
   Simple Linear Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#manipulate-the-fitting-by-hand">
   Manipulate the fitting by hand
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimating-learning-model-coefficients">
   Estimating (“Learning”) Model Coefficients
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpret-an-ols-regression-fit">
   Interpret an OLS Regression fit
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-model-coefficients">
     Interpreting Model Coefficients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-the-model-for-prediction">
   Using the Model for Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plotting-the-least-squares-regression-line">
   Plotting the least squares regression line
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confidence-in-our-model">
   Confidence in our Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing-and-p-values">
   Hypothesis Testing and p-values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-well-does-the-model-fit-the-data">
   How Well Does the Model Fit the data?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">Markdown</span><span class="p">,</span> <span class="n">display</span>

<span class="kn">import</span> <span class="nn">numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="lab-1-introduction-to-linear-regression">
<h1>Lab 1: Introduction to Linear Regression<a class="headerlink" href="#lab-1-introduction-to-linear-regression" title="Permalink to this headline">¶</a></h1>
<p>Authored by <em>Todd Gureckis</em><br />
Aspects borrowed from <a class="reference external" href="https://github.com/justmarkham/DAT4">General Assembly’s Data Science</a> course which claims to have <em>adapted materials from Chapter 3 of <a class="reference external" href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning</a></em></p>
<p>Welcome to the first lab!  You have passed the first part of the class learning the basics of Python and Jupyter with flying colors.  Now you are ready to learn some of the mechanics of running a regression analysis.  In the first part of the lab we’ll just cover the details on how to run regressions in Python and some of the conceptual issue involved in the interpretation and fitting of a regression analysis.  Then in the subsequent days of the lab you will put this knowledge to work on a variety of interesting types of data.</p>
<img src="https://imgs.xkcd.com/comics/curve_fitting_2x.png" width="400"><p>Ok, why are we basing our first lab around the concept of linear regression?  Well it turns out regression (and correlation) are two of the workhorses of a cognitive scientist’s toolkit.  Linear regression models are highly interpretable, are used in many places in cognitive science, are fast and simply to perform, and expose some of the basic issues in modeling data.  If there is one tool I use over and over in my work it is linear regression of some type!</p>
<p>Some example uses:</p>
<ul class="simple">
<li><p>Often linear regression is used to “control” for nusiance variables in the study that might be confounded.   For example by fitting a linear multiple regression model you can remove the variance in our data attributable to known sources and then model the <strong>residuals</strong> (more on this later).</p></li>
<li><p>The standard analysis techniques for fMRI are based on the General Linear Model which is a kind of generalization of multiple linear regression.  Thus you are getting some of the basics for fMRI analysis.</p></li>
<li><p>Regression is often used to measure latent cognitive variables.  For instance one might be interested in how reaction time changes as a function of task difficulty (e.g., number of distractors present in a task).  Here linear regression is nice because the slope of the regression provides an interprable number which explains how reaction time changes as a function of the task.</p></li>
<li><p>If you were interested in the effect of age on cognitive performance in some task, a linear regression might help you characterize that pattern (although you’d want to check that the linear assumption is valid… more on that later).</p></li>
</ul>
<p>Trust me, it is everwhere!</p>
<p>Here’s a weird thing you might not know… There is a long running joke/meme about companies that claim to use “machine learning” to analyze data to make “business insights” actually use linear regression (well a special type called logistic regression).  The issue is that complex linear models, particularly multiple linear regression with many input predictors, can mimic a lot of the power of things like neural networks while being more stable, computationally tractable, etc…  So, even if a machine learning company doesn’t use linear regression in their final product, often you have to show that your model does <strong>better</strong> than linear regression to be useful.  Thus, linear regression is like the default modeling approach that is often hard to beat!</p>
<img src="images/linear-regression-is-not-machine-learning-is-change-my-mind-45626240.png" width="300"><p>So you are going to learn some basic machine learning in this lab!  Seriously!  For simplicity we are going to use the <a class="reference external" href="https://www.statsmodels.org/stable/index.html">statsmodels</a> python package because it has a lot of nice outputs which are helpful for interpreting regressions.  However, you could do almost all of the same stuff using the <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> package which is a more general package for machine learning than can perform various types of sophisticated regression, classification, clustering, and dimensionality reduction steps.</p>
<div class="section" id="getting-started-with-some-data">
<h2>Getting started with some data<a class="headerlink" href="#getting-started-with-some-data" title="Permalink to this headline">¶</a></h2>
<p>Let’s get started by loading in some data.  At this point you should be an expert in learning data into a pandas datafrom from a .csv file.</p>
<div class="alert alert-info" role="alert">
  <strong>Question 1</strong> <br>
    Please load the data set located at <b>http://gureckislab.org/courses/fall19/labincp/data/parenthood.csv</b> into a dataframe called <b>ph_df</b> and inspect the column headers, etc..
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div><p>You should see that the data contains four columns called <strong>dadsleep</strong>, <strong>babysleep</strong>, <strong>dadgrump</strong>, and <strong>day</strong>.  This is data set created by Danielle Navarrro in her textbook that explores the factors that lead to the dad being grumpy (I have a 1 year old at home so this data is particularly relevant to me!).</p>
<div class="alert alert-info" role="alert">
  <strong>Question 2</strong> <br>
    When we do a regression there are two types of variables.  Some variables are known as features or predictors.  Often a single variable is known as the response variable or the predicted value.  If we are interested in what makes the dad grumpy what are the predictors and what is the response variable?
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div><p>Let’s look at the data! As we described in the prior labs, the first step of exploratory data analysis is often to look at your data.</p>
<div class="alert alert-info" role="alert">
  <strong>Question 3</strong> <br>
    Using the seaborn `scatterplot()` command make a scatter plot of how grumpiness changes for each of the three other variables.</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div><div class="alert alert-info" role="alert">
  <strong>Question 4</strong> <br>
    Based on your exploratory view of the data what do you think are the relationship within this data set?
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div></div>
<div class="section" id="simple-linear-regression">
<h2>Simple Linear Regression<a class="headerlink" href="#simple-linear-regression" title="Permalink to this headline">¶</a></h2>
<p>Simple linear regression is an approach for predicting a <strong>quantitative response</strong> using a <strong>single feature</strong> (or “predictor” or “input variable”). It takes the following form:</p>
<p><span class="math notranslate nohighlight">\(y = \beta_0 + \beta_1x\)</span></p>
<p>What does each term represent?</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the response</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the feature</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span> is the intercept</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_1\)</span> is the coefficient for x</p></li>
</ul>
<p>Together, <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> are called the <strong>model coefficients</strong>. To create your model, you must “learn” the values of these coefficients. And once we’ve learned these coefficients, we can use the model to make predictions!</p>
<p>What do you mean by “learn”?  Well you are probably more familiar with the phrase “fit” meaning we adjust the settings of the model coefficients (aka as parameters) until the line seems like a good summary of the data.  Fitting thus mean adjusting some internal numbers so that the better reflect the underlying data set.  Well when a human (or machine) learns it, it is in some sense of the same thing.  We change the connections of the weights (or parameters) inside our brains to help us better predict our environment.  For instance if your roommate is prone to late night partying and being grumpy the next day you might mentally fit a model to the experiences you have and “learn” what features are predictive of them being grumpy.  So basically fitting a linear regression model is the same as doing basic machine learning! Wow!</p>
</div>
<div class="section" id="manipulate-the-fitting-by-hand">
<h2>Manipulate the fitting by hand<a class="headerlink" href="#manipulate-the-fitting-by-hand" title="Permalink to this headline">¶</a></h2>
<p>Before we get into using the computer to “fit” our data, let’s start simple and do things by hand.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">20</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">intercept</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">plot_grumpiness</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">intercept</span><span class="o">-</span><span class="n">slope</span><span class="o">*</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span>
    <span class="n">resid</span> <span class="o">=</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="o">-</span><span class="n">predict</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">400</span><span class="p">)</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">intercept</span><span class="o">-</span><span class="n">slope</span><span class="o">*</span><span class="n">x1</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="p">,</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="p">,</span><span class="s1">&#39;ko&#39;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="c1">#ax.plot(ph_df.dadsleep, ph_df.dadgrump-resid,&#39;o&#39;,markersize=4,markeredgecolor=&#39;r&#39;, markeredgewidth=.4, markerfacecolor=&#39;white&#39;)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;dad sleep&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;dad grumpiness&quot;</span><span class="p">)</span>

    <span class="c1">#ax.vlines(ph_df.dadsleep, ph_df.dadgrump, ph_df.dadgrump-resid,&#39;r&#39;,linewidth=0.5)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-info" role="alert">
  <strong>Question 5</strong> <br>
    Using the slider above, adjust the location of the line to best fit the data represented by the black dots.  What value did you get for the slope and intercept?
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div><p>The next plot show what are known as the <strong>residuals</strong> between the actual data points (black) and the regression line (blue).  As you can see the total amount of red changes depending on which line you use.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">20</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">intercept</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">plot_grumpiness</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">intercept</span><span class="o">-</span><span class="n">slope</span><span class="o">*</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span>
    <span class="n">resid</span> <span class="o">=</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="o">-</span><span class="n">predict</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">400</span><span class="p">)</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">intercept</span><span class="o">-</span><span class="n">slope</span><span class="o">*</span><span class="n">x1</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="p">,</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="p">,</span><span class="s1">&#39;ko&#39;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="p">,</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="o">-</span><span class="n">resid</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mf">.4</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;dad sleep&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;dad grumpiness&quot;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="p">,</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="p">,</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="o">-</span><span class="n">resid</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-info" role="alert">
  <strong>Question 6</strong> <br>
    Find the best fit line you found from the plot above and compare it to different settings of the parameters.  What do you notice about the lines that seem to fit well and the overall amount of red int he plot?
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div></div>
<div class="section" id="estimating-learning-model-coefficients">
<h2>Estimating (“Learning”) Model Coefficients<a class="headerlink" href="#estimating-learning-model-coefficients" title="Permalink to this headline">¶</a></h2>
<p>The mechanics of fitting a line to some data (aka as “learning” the model coefficients or parameters) is best left to the computer.  The reason is that for some dataset what is the “best fit” line might end up being too subjective (different people would prefer a different line).  Also when we get to doing fMRI analysis you might repeat the regression for hundreds of thousands of individual voxels.  This would take a lot of tinkering by hand to solve.</p>
<p>Generally speaking, coefficients are estimated using the <strong>least squares criterion</strong>, which means we are find the line (mathematically) which minimizes the <strong>sum of squared residuals</strong> (or “sum of squared errors”):</p>
<img src="images/08_estimating_coefficients.png" width="600"><p>What elements are present in the diagram?</p>
<ul class="simple">
<li><p>The black dots are the <strong>observed values</strong> of x and y.</p></li>
<li><p>The blue line is our <strong>least squares line</strong>.</p></li>
<li><p>The red lines are the <strong>residuals</strong>, which are the distances between the observed values and the least squares line.</p></li>
</ul>
<p>How do the model coefficients relate to the least squares line?</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span> is the <strong>intercept</strong> (the value of <span class="math notranslate nohighlight">\(y\)</span> when <span class="math notranslate nohighlight">\(x\)</span>=0)</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_1\)</span> is the <strong>slope</strong> (the change in <span class="math notranslate nohighlight">\(y\)</span> divided by change in <span class="math notranslate nohighlight">\(x\)</span>)</p></li>
</ul>
<p>Here is a graphical depiction of those calculations:</p>
<img src="images/08_slope_intercept.png" width="450"><p>Let’s use the <strong>statmodels</strong> python package to estimate the model coefficients (aka “fit” the model) instead!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this is the standard import if you&#39;re using &quot;formula notation&quot; (similar to R)</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1"># create the fitted model in one line</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;dadgrump ~ dadsleep&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ph_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A couple of points here… First is that we use the <code class="docutils literal notranslate"><span class="pre">smf.ols()</span></code> function which does an “ordinary least squares” fit.  This is the type of fit which tries to minimze the sum of the squared residuals.  There are other types of fitting proceedures such as weighted least squares which is used when you expect the variance of the predicted variable to changes with the input predictor as well as its mean value.  We don’t worry abou that for this class though.</p>
<p>The second is that we provide the <code class="docutils literal notranslate"><span class="pre">ols()</span></code> function with the pandas dataframe we are working with (<code class="docutils literal notranslate"><span class="pre">ph_df</span></code> according to the instructions in the first step of the lab) and then provide a formula.  The formula expresses our “model” and is which variables in the data frame we are trying to relate.  Here the formula <code class="docutils literal notranslate"><span class="pre">dadgrump</span> <span class="pre">~</span> <span class="pre">dadsleep</span></code> means that we want to predict <code class="docutils literal notranslate"><span class="pre">dadgrump</span></code> values given <code class="docutils literal notranslate"><span class="pre">dadsleep</span></code> values.  So you think of <code class="docutils literal notranslate"><span class="pre">dadgrump</span></code> as our “y value” and <code class="docutils literal notranslate"><span class="pre">dadsleep</span></code> are our x value.</p>
<div class="alert alert-info" role="alert">
  <strong>Question 7</strong> <br>
    Look at the output parameters from the ols fitting proceedure.  How do they compare to the ones you fitted by hand?
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div></div>
<div class="section" id="interpret-an-ols-regression-fit">
<h2>Interpret an OLS Regression fit<a class="headerlink" href="#interpret-an-ols-regression-fit" title="Permalink to this headline">¶</a></h2>
<p>Ok, so we did a model fit.  We are like totally machine learning experiments now since we taught a model!  But the cool thing about linear regression is that the model strucutre is <em>easily interpretable</em>.  So what can we learn from the fit?</p>
<div class="section" id="interpreting-model-coefficients">
<h3>Interpreting Model Coefficients<a class="headerlink" href="#interpreting-model-coefficients" title="Permalink to this headline">¶</a></h3>
<p>How do we interpret the <code class="docutils literal notranslate"><span class="pre">dadsleep</span></code> coefficient?</p>
<ul class="simple">
<li><p>A “unit” increase in hours data sleep is <strong>associated with</strong> a -8.9367 “unit” decrease (because it is negative) in grumpiness.  This kind of make sense. More sleep = less grumpy!</p></li>
</ul>
<p>Note that if an increase in sleep was associated with a <strong>increase</strong> in grumpiness, the <code class="docutils literal notranslate"><span class="pre">dadsleep</span></code> coefficient would be <strong>positive</strong>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Intercept</span></code> coefficent is 125.95.  This means that if dad gets no sleep at all his grumpiness will be at a very high level of 125.95!  Bad news.</p>
</div>
</div>
<div class="section" id="using-the-model-for-prediction">
<h2>Using the Model for Prediction<a class="headerlink" href="#using-the-model-for-prediction" title="Permalink to this headline">¶</a></h2>
<p>Let’s say that mom comes into the picture here.  Mom wants to anticipate how grumpy dad will be today.  So she measures his sleep last night and finds that he slept 6 hours.  What is her best guess about what the grumpiness level will be today?</p>
<p>Well she could go back to the data and find a similar day where dad got 6 hours of sleep and average those together or grab one at random and repeat the same guess.  However, since we just fit our linear regression equation we can use that model for prediction.  In particular, remember:</p>
<div class="math notranslate nohighlight">
\[y = \beta_0 + \beta_1x\]</div>
<div class="math notranslate nohighlight">
\[y = 125.956292 + -8.936756 \times 6\]</div>
<div class="alert alert-info" role="alert">
  <strong>Question 8</strong> <br>
    Use your python calculator skills to predict the level of grumpiness for a dad who got 6 hours of sleep.  Why is using the regression line a better way to make predictions than to grab similar cases and just use those?
</div><div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div><p>Of course, we can also use Statsmodels to make the prediction:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># you have to create a DataFrame since the Statsmodels formula interface expects it</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;dadsleep&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">]})</span>
<span class="n">X_new</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-the-least-squares-regression-line">
<h2>Plotting the least squares regression line<a class="headerlink" href="#plotting-the-least-squares-regression-line" title="Permalink to this headline">¶</a></h2>
<p>Let’s take a look at the best fit line.  There are two very easy ways to do this.  One is using seaborn’s regplot which includes within the function an entire step to plot the regression line:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="s1">&#39;dadgrump&#39;</span><span class="p">,</span><span class="s1">&#39;dadsleep&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">ph_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Alternatively if we are concerned the maybe we don’t understand exactly what seaborn is doing we can plot the output of our fit from the <code class="docutils literal notranslate"><span class="pre">ols()</span></code> command:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="c1"># create a DataFrame with the minimum and maximum values of sleep</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;dadsleep&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="o">.</span><span class="n">max</span><span class="p">()]})</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>  <span class="c1"># predict for the two data points using the fitted model in lm</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ph_df</span><span class="o">.</span><span class="n">dadsleep</span><span class="p">,</span> <span class="n">ph_df</span><span class="o">.</span><span class="n">dadgrump</span><span class="p">,</span><span class="s1">&#39;ko&#39;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="s1">&#39;-&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;dad sleep&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;dad grumpiness&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="confidence-in-our-model">
<h2>Confidence in our Model<a class="headerlink" href="#confidence-in-our-model" title="Permalink to this headline">¶</a></h2>
<p>Statsmodels calculates 95% confidence intervals for our model coefficients, which are interpreted as follows: If the population from which this sample was drawn was <strong>sampled 100 times</strong>, approximately <strong>95 of those confidence intervals</strong> would contain the “true” coefficient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the confidence intervals for the model coefficients</span>
<span class="n">lm</span><span class="o">.</span><span class="n">conf_int</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Keep in mind that we only have a <strong>single sample of data</strong>, and not the <strong>entire population of data</strong>. The “true” coefficient is either within this interval or it isn’t, but there’s no way to actually know. We estimate the coefficient with the data we do have, and we show uncertainty about that estimate by giving a range that the coefficient is <strong>probably</strong> within.</p>
<p>Note that using 95% confidence intervals is just a convention. You can create 90% confidence intervals (which will be more narrow), 99% confidence intervals (which will be wider), or whatever intervals you like.</p>
</div>
<div class="section" id="hypothesis-testing-and-p-values">
<h2>Hypothesis Testing and p-values<a class="headerlink" href="#hypothesis-testing-and-p-values" title="Permalink to this headline">¶</a></h2>
<p>Closely related to confidence intervals is <strong>hypothesis testing</strong>. Generally speaking, you start with a <strong>null hypothesis</strong> and an <strong>alternative hypothesis</strong> (that is opposite the null). Then, you check whether the data supports <strong>rejecting the null hypothesis</strong> or <strong>failing to reject the null hypothesis</strong>.</p>
<p>(Note that “failing to reject” the null is not the same as “accepting” the null hypothesis. The alternative hypothesis may indeed be true, except that you just don’t have enough data to show that.)</p>
<p>As it relates to model coefficients, here is the conventional hypothesis test:</p>
<ul class="simple">
<li><p><strong>null hypothesis:</strong> There is no relationship between dad sleep and grumpiness (and thus <span class="math notranslate nohighlight">\(\beta_1\)</span> equals zero)</p></li>
<li><p><strong>alternative hypothesis:</strong> There is a relationship between dad sleep and dad grumpinss (and thus <span class="math notranslate nohighlight">\(\beta_1\)</span> is not equal to zero)</p></li>
</ul>
<p>How do we test this hypothesis? Intuitively, we reject the null (and thus believe the alternative) if the 95% confidence interval <strong>does not include zero</strong>. Conversely, the <strong>p-value</strong> represents the probability that the coefficient is actually zero:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the p-values for the model coefficients</span>
<span class="n">lm</span><span class="o">.</span><span class="n">pvalues</span>
</pre></div>
</div>
</div>
</div>
<p>If the 95% confidence interval <strong>includes zero</strong>, the p-value for that coefficient will be <strong>greater than 0.05</strong>. If the 95% confidence interval <strong>does not include zero</strong>, the p-value will be <strong>less than 0.05</strong>. Thus, a p-value less than 0.05 is one way to decide whether there is likely a relationship between the feature and the response. (Again, using 0.05 as the cutoff is just a convention.)</p>
<p>In this case, the p-value for dad sleep is far less than 0.05, and so we <strong>believe</strong> that there is a relationship between sleep and grumpiness.</p>
<p>Note that we generally ignore the p-value for the intercept.</p>
</div>
<div class="section" id="how-well-does-the-model-fit-the-data">
<h2>How Well Does the Model Fit the data?<a class="headerlink" href="#how-well-does-the-model-fit-the-data" title="Permalink to this headline">¶</a></h2>
<p>The most common way to evaluate the overall fit of a linear model is by the <strong>R-squared</strong> value. R-squared is the <strong>proportion of variance explained</strong>, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the <strong>null model</strong>. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)</p>
<p>R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. Here’s an example of what R-squared “looks like” fit to a different dataset:</p>
<img src="images/08_r_squared.png" width="500"><p>You can see that the <strong>blue line</strong> explains some of the variance in the data (R-squared=0.54), the <strong>green line</strong> explains more of the variance (R-squared=0.64), and the <strong>red line</strong> fits the training data even further (R-squared=0.66). (Does the red line look like it’s overfitting?)</p>
<p>Let’s calculate the R-squared value for our simple linear model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the R-squared value for the model</span>
<span class="n">lm</span><span class="o">.</span><span class="n">rsquared</span>
</pre></div>
</div>
</div>
</div>
<p>Is that a “good” R-squared value? It’s hard to say. The threshold for a good R-squared value depends widely on the domain. Therefore, it’s most useful as a tool for <strong>comparing different models</strong>.</p>
<img src="https://imgs.xkcd.com/comics/linear_regression_2x.png" width="300"><p>So far we have been pulling information from our fitted model piece by piece.  However, there is a nice summary command that lets you access a bunch of information about your regression at once.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lm</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This include most of the numbers we discussed above and a few more things discussed in the book chapter reading on regression.</p>
<div class="alert alert-info" role="alert">
  <strong>Question 9</strong> <br>
    You know know the basics of linear regression! Congrats.  Now I want you to work on analyzing a new data set in the same way.  All the pieces you need are above or we have encountered in previous lab.  Please obtain the dataset on advertising available as a CSV here: http://gureckislab.org/courses/fall19/labincp/data/advertising.csv
<ul>
<li>Read in the data frame</li>
<li>Look at the structure of the columns (note the column names are case sensitive)</li>
<li>Plot the relationship between TV advertising and Sale, the relationship between Radio and Sales, and the relationship between Newspaper and Sales.  What does this visual exploration of the data suggest? (bonus if you can use subplots() to make it a single figure)</li>
<li>Perform a separate simple OLS regression of each of the three feature sets on the response variable.  Remember that you might want to call your variables different names to keep things separate.  For isntance instead of storing the result of each regression in a varable called <b>lm</b> you might want a different lm variable names for each of the simple regressions you run</li>
<li>Plot the best fit line for each of the three patterns</li>
<li>Describe the best fitting parameters for each of the three dataset.  What are the coefficients in each model, are the slopes different than zero (given the hypothesis test)?  What is the R^2 value?</li>
<li>In a markdown cell write a brief summary of what you think is going on in this data.  What types of advertising are most effective for sales?  If you had a limited budget which one would you focus your advertising dollars on?</li>
</ul>
</div><p>A hint: what are the <strong>features</strong>?</p>
<ul class="simple">
<li><p>TV: advertising dollars spent on TV for a single product in a given market (in thousands of dollars)</p></li>
<li><p>Radio: advertising dollars spent on Radio</p></li>
<li><p>Newspaper: advertising dollars spent on Newspaper</p></li>
</ul>
<p>What is the <strong>response</strong>?</p>
<ul class="simple">
<li><p>Sales: sales of a single product in a given market (in thousands of widgets)</p></li>
</ul>
<div class="alert alert-warning" role="alert">
  <strong>Your Answer</strong> <br>
  Delete this text and put your answer here.  The code for your analysis should appear in the cells below.
</div></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./labs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Todd Gureckis<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>